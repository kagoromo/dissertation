\documentclass{article}

\usepackage{hyperref}
\usepackage{geometry}
\usepackage{amssymb}
\usepackage{xcolor}
\usepackage{listings}

\usepackage{xltxtra,fontspec,xunicode}
\defaultfontfeatures{Scale=MatchLowercase}
\setromanfont[Mapping=tex-text]{PT Serif}
\setsansfont[Mapping=tex-text]{PT Serif}

% Set your name here
\def\name{Lindsey Kuper}

% The following metadata will show up in the PDF properties
\hypersetup{
  colorlinks = true,
  urlcolor = cyan,
  pdfauthor = {\name},
  pdftitle = {\name: Research Statement},
  pdfsubject = {Research Statement},
  pdfpagemode = UseNone
}
\urlstyle{same}

\geometry{
  body={6.6in, 9.0in},
  left=0.95in,
  top=1.0in
}

% Customize page headers
\pagestyle{myheadings}
\markright{\name: Research Statement} 
\thispagestyle{empty}

% Custom section fonts
\usepackage{sectsty}
\sectionfont{\mdseries\Large}
\subsectionfont{\mdseries\itshape\large}

\input{../latex_common/lang}

% Editing marks
\input{../latex_common/editingmarks}

% Other presentational stuff
\input{../latex_common/style}

%  Use the @ symbol for simple inline code within prose:
\lstMakeShortInline[]@

\begin{document}

\title{Research Statement}

\author{\name}

\date{\today}

\maketitle

\lk{Some of this wording is borrowed from Aaron Turon's research statement.}

\noindent My research lies broadly in the area of programming
languages, with the goal of creating tools, techniques, and
abstractions that support \emph{compositional reasoning} about
programs, proofs, and processes, especially those that do not
immediately appear to compose well.  For the last few years, my focus
has been on parallel and distributed programming models.  Below I
discuss my work in more detail, beginning in Sections~\ref{lvars} and
\ref{quasi} with my work on lattice-based data structures, or
\emph{LVars}, for deterministic and \emph{quasi-deterministic}
parallelism.  Then, in Section~\ref{crdts}, I discuss my ongoing study
of the relationship between LVars and \emph{conflict-free replicated
  data types} for eventually consistent distributed systems, and what
I plan to work on next.  For brevity, I omit my previous work on
\emph{relational programming}~\cite{lambdae}, \emph{multi-language
  parametricity}~\cite{multilang-talk}, or \emph{testing CPU semantic
  specifications}~\cite{tsl-tr}.

\section{LVars: lattice-based data structures for deterministic parallelism}\label{lvars}

\lk{Something like this?
A fundamental challenge of parallel programming is that programs can
behave in unexpected ways as a result of unpredictable interactions
between parallel tasks.  So-called \emph{irregular} parallel
applications---in which the work an algorithm must do and the
potential for parallelizing it depend on the particular input being
processed---exacerbate this challenge: since work has to be
dynamically scheduled, unpredictable inter-task interactions are
inevitable.}

\emph{Deterministic-by-construction} parallel programming models
guarantee that programs written using them will have the same
observable behavior on every run, offering the promise of freedom from
subtle, hard-to-reproduce bugs caused by schedule nondeterminism.  In
order to guarantee determinism, though, deterministic-by-construction
models must sharply restrict the sharing of state between parallel
tasks.  Shared state, when not disallowed entirely, is restricted to a
single type of shared data structure, such as single-assignment
locations, known as \emph{IVars}~\cite{IStructures, CnC}, or blocking
FIFO queues, as in Kahn process networks~\cite{Kahn-1974}.  These
approaches limit the kinds of deterministic algorithms that can be
expressed---efficiently or at all---within the model.

\lk{TODO: say something about irregular parallel applications, where
  the amount of available parallelism depends on the data being
  processed.}

My work introduces \emph{lattice-based data structures}, or
\emph{LVars}~\cite{LVars-paper, LVars-TR}, which generalize the above
approaches to allow multiple assignments to shared locations.  Writes
to an LVar update its value to the least upper bound of the old and
new values, ensuring that its state is monotonically increasing with
respect to an application-specific \emph{lattice}.  Along with
monotonically increasing writes, LVars ensure determinism by allowing
only ``threshold'' reads that block until a lower bound (\ie, an
element belonging to a restricted subset of the lattice) is reached.
Together, monotonic writes and threshold reads yield a provably
deterministic parallel programming model: programs will always have
the same observable outcome in spite of parallel execution and
schedule nondeterminism.

Our determinism result is \emph{lattice-generic}: threads can
communicate through \emph{any} shared data structure, so long as the
states the data structure can take on can be viewed as elements of a
lattice and updates are monotonically increasing.  This generality
allows a programming model based on LVars to subsume existing
deterministic parallel programming models.  For example, a lattice of
channel histories with a prefix ordering allows LVars to represent
FIFO channels that implement a Kahn process network, whereas
instantiating the model with a lattice with one ``empty'' state and
multiple ``full'' states (where $\forall{i}.\; \mathit{empty} <
\mathit{full_i}$) results in a parallel single-assignment language.
Different instantiations of the LVars model result in a wide-ranging
family of deterministic parallel languages.

We put LVars into practice in \emph{LVish}~\cite{LVish}, a Haskell
library for guaranteed-deterministic parallel programming.  The LVish
library provides the \emph{\lstinline|Par| monad}, a mechanism for
encapsulating parallel computation, and enables a notion of
lightweight, library-level threads to be employed with a custom
work-stealing scheduler.  LVish also provides a variety of
lattice-based data structures (\eg, sets, maps, graphs) that support
concurrent insertion, but not deletion, during @Par@ computations.
Users may implement their own lattice-based data structures as well,
and LVish provides tools to facilitate the definition of such
user-defined LVars.

\section{Quasi-deterministic parallel programming with LVars and LVish}\label{quasi}

The LVars model described above guarantees determinism, but is not as
general-purpose as one might hope.  Consider a parallel graph
traversal, implemented using a monotonically growing set of ``seen''
nodes, where neighbors of seen nodes are fed back into the set until
it reaches a fixed point.  Such fixpoint computations are ubiquitous,
and would seem to be a perfect match for the LVars model due to their
use of monotonicity, but they are not expressible using the threshold
reads described above because they rely on \emph{negative} information
about a data structure, \ie, on the \emph{absence} of certain writes
to it.  In a graph traversal, for example, neighboring nodes should
only be explored if the current node is \emph{not yet} in the set, and
a fixpoint is reached only if no new neighbors are found.

My work in POPL '14~\cite{Freeze-paper, Freeze-TR} extends LVars in
two ways that make such computations possible.  First, we add the
ability to \emph{freeze} an LVar, allowing its contents to be read
immediately and exactly without blocking. Freezing imposes the
trade-off that, once an LVar has been frozen, any further writes that
would change its value instead raise an exception.  Second, we add the
ability to attach \emph{event handlers} to an LVar, triggering a
callback to run asynchronously whenever events arrive (in the form of
monotonic updates to the LVar).  Crucially, it is possible to check
for \emph{quiescence} of a group of handlers, which can be used to
tell that a fixpoint has been reached.

Together, handlers and freezing enable an expressive and useful style
of parallel programming.  We prove that in a language where
communication takes place through these extended LVars, programs are
at worst \emph{quasi-deterministic}: on every run, they either produce
the same answer or raise an error.  The error case can only be caused
by a write-after-freeze exception, and error messages can pinpoint the
exact racing pair of write and freeze operations so that the
programmer can easily correct the bug.

We demonstrate the viability of our approach by extending the LVish
library with support for handlers and freezing.  As part of these
extensions, we add the ability to annotate a @Par@ computation with an
\emph{effect level}, allowing fine-grained specification of the
effects that a given computation is allowed to perform.  For instance,
since freezing introduces quasi-determinism, a computation annotated
with a deterministic effect level is not allowed to perform a freeze.
Thus, the \emph{static type} of an LVish computation reflects its
determinism or quasi-determinism guarantee.  Furthermore, if a freeze
is guaranteed to be the \emph{last} effect that occurs in an LVar
computation, then it is impossible for that freeze to race with a
write, ruling out the possibility of a run-time write-after-freeze
exception.  LVish exposes a @runParThenFreeze@ operation that captures
this ``freeze-last'' idiom and has a deterministic effect level.  We
have used the LVish library, extended with handlers and freezing, to
achieve good parallel speedup in application domains ranging from
static analysis~\cite{Freeze-paper} to
bioinformatics~(\cite{effectzoo}, to appear in PLDI '14).

\section{Joining forces: LVars and conflict-free replicated data types}\label{crdts}

Replication of data across physical locations is of fundamental
importance in distributed systems: it makes systems more robust to
data loss and allows for good data locality.  However, it presents the
dilemma of how to resolve conflicts between replicas that differ,
particularly in the case of \emph{highly available} distributed
systems~\cite{dynamo} that give up on strict consistency in favor of
\emph{eventual consistency}~\cite{vogels-ec}.  Fortunately,
\emph{conflict-free replicated data types} (CRDTs)~\cite{crdts,
  crdts-tr} provide a simple mathematical framework for reasoning
about and enforcing the eventual consistency of replicated objects in
a distributed system.  In particular, \emph{state-based} or
\emph{convergent} replicated data types, abbreviated as \emph{CvRDTs},
leverage the mathematical properties of lattices to guarantee that all
replicas of an object (for instance, in a distributed database)
eventually agree.

CvRDTs use lattice properties to ensure eventual consistency across
replicas in a way that is closely analogous to how LVars use lattice
properties to ensure determinism across parallel executions.
Therefore a sensible next research question is: can we use lessons
from the literature on replicated data types to improve the LVars
model, and vice versa?  In my current work (\cite{joining-wodet}, to
appear in WoDet '14), I am approaching this question in both
directions.  In one direction, I am using techniques from the CRDT
literature to develop LVars that \emph{emulate} non-monotonic updates,
such as sets that support removal of elements and counters that can be
decremented as well as incremented.  In the other direction, I show
how LVar-style threshold reads apply to the setting of CvRDTs.  Since
threshold reads guarantee that the order in which updates occur cannot
be observed, they can prevent queries from returning inconsistent
intermediate states, ensuring a greater degree of consistency in
CvRDTs.  When \emph{all} reads are threshold reads, we should be able
to guarantee strong consistency---and only at the (potential) price of
read availability, never write availability. Moreover, in practice, a
combination of threshold reads and regular reads should enable a
notion of dynamically configurable, \emph{pay-as-you-go consistency}
between the extremes of eventual consistency and strong consistency
that today's systems offer.

\bibliographystyle{plain}
\newcommand{\myname}[0]{\textbf{Lindsey Kuper}}
\bibliography{../latex_common/refs}

\end{document}
