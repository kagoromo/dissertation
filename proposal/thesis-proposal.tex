\documentclass{article}
\usepackage{amsmath,amssymb,amsthm}
\usepackage{color}
\usepackage{hyperref}
\usepackage{stmaryrd}
\usepackage{float}
\usepackage{listings}
\usepackage{graphicx}
\usepackage{fullpage}
\usepackage{times}

% Editing marks.
\input{../latex_common/editingmarks}

% Other presentational stuff
\input{../latex_common/style}

\begin{document}

\title{Thesis Proposal: \\
  Lattice-based Data Structures for \\
  Deterministic Parallel and Distributed Programming}

\author{Lindsey Kuper \\ Indiana University}

\date{Draft of \today}

\maketitle

\begin{abstract}
  Abstract goes here.
\end{abstract}

\section{Introduction}

\section{Deterministic-by-construction parallel programming}

Parallel programming is notoriously difficult.  \lk{Difficult to who?}
A fundamental reason for this notoriety is that programs can yield
inconsistent results, or even crash, due to unpredictable interactions
between parallel tasks.  But it doesn't have to be this way:
\emph{deterministic-by-construction} parallel programming models offer
the promise of freedom from subtle, hard-to-reproduce nondeterministic
bugs in parallel code.

A deterministic-by-construction programming model is one that ensures
that all programs written using the model have the same
\emph{observable behavior} every time they are run.  What does
``observable behavior'' mean?  There are many ways to define what is
observable about a program.  Clearly, we do \emph{not} wish to
preserve behaviors such as running time across multiple
runs---ideally, a deterministic-by-construction parallel program will
run faster when more parallel resources are available!  In this
proposal, we define the observable behavior of a program to be the
value to which it evaluates.  Specifically, we do not count the
behavior of the scheduler as observable.  Indeed, the purpose of our
deterministic-by-construction model will be to allow tasks to be
scheduled dynamically and unpredictably, without allowing such
\emph{schedule nondeterminism} to affect programs' observable
behavior.

\section{Existing approaches to determinism by construction}

Shared state between computations allows the possibility for
\emph{data races} that allow schedule nondeterminism to be
observed---if one thread writes $3$ to a shared location while another
writes $4$, then another thread that reads and returns the value will
nondeterministically return $3$ or $4$ depending on how the threads
are scheduled to run.  Therefore, deterministic parallel programming
models necessarily limit sharing of mutable state between parallel
tasks.


Introduce the problem.

Explain, at a high level, what my work does to solve the problem.

Explain what the structure of this proposal will be.

This citation \cite{LVars-TR} is here to make LaTeX happy.

\section{Background}

\section{Thesis statement}

\lk{This format ripped off from Josh Dunfield.}

With the above background, I can state my thesis:

\lk{``novel, feasible and useful''}

\lk{ ``Lattice-based data structures, whose contents grow
  monotonically with respect to an application-specific lattice and
  for which the order in which information is added is not observable,
  are a novel, feasible, and useful means of guaranteeing the
  determinism of parallel programs.''  This isn't right.  It's not
  ``here's a parallel program, let's apply lattice-based data
  structures to it and guarantee its determinism that way!''  It's,
  ``Let's build lattice-based data structures into the programming
  model to start.''  }

\begin{quote}
  Lattice-based data structures\lk{, whose contents grow monotonically
  with respect to an application-specific lattice and for which the
  order in which information is added is not observable,} are a
  practical, flexible, and mathematically rigorous foundation for
  deterministic parallel and distributed programming.
\end{quote}

\lk{Better...I'm still unsure about ``and distributed''.}

\section{Technical overview}

\section{Freezing, handlers, and quasideterminism}

\section{LVars and CRDTs}

In this section, I will discuss the relationship between the LVars
model I've described and the mathematical framework of
\emph{conflict-free replicated data types} that distributed systems
research have developed for reasoning about and enforcing the eventual
consistency of distributed replicated objects.

\subsection{Replication and eventual consistency}

Distributed systems often involve \emph{replication} of data objects
across a number of physical locations.  Reasons to replicate data may
include:
\begin{itemize}
\item Robustness to failure: if multiple replicas of an object exist,
  we are less likely to lose that object if part of our system fails.

\item Proximity: objects should be close to clients who need them.

\item Parallelism: different processes simultaneously operating on the
  same object may each need their own copy. \lk{Explain how this is
    different from the above point.}
\end{itemize}
If a system of distributed, replicated objects behaved
indistinguishably from the model a lot of us are used to programming
with, in which all our data and all our computation are on one
machine, then we would not need to concern ourselves with special
techniques to support replication.  \lk{This is worded awkwardly ---
  look at the CRDT papers for inspiration?}  Unfortunately, this is
not the case.

\section{Related work}

\section{Road map}

\bibliographystyle{abbrvnat}
\bibliography{../latex_common/refs}

\end{document}
