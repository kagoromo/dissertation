\documentclass{article}
\usepackage{amsmath,amssymb,amsthm}
\usepackage{color}
\usepackage{hyperref}
\usepackage{stmaryrd}
\usepackage{float}
\usepackage{listings}
\usepackage{graphicx}
\usepackage{fullpage}
\usepackage{times}

% Editing marks.
\input{../latex_common/editingmarks}

% Other presentational stuff
\input{../latex_common/style}

\begin{document}

\title{Thesis Proposal: \\
  Lattice-based Data Structures for 
  Deterministic Parallel and Distributed Programming}

\author{Lindsey Kuper \\ Indiana University}

\date{Draft of \today}

\maketitle

\begin{abstract}
  Deterministic-by-construction parallel programming models guarantee
  that programs written using them will have the same observable
  behavior on every run, offering freedom from subtle,
  hard-to-reproduce bugs caused by schedule nondeterminism.  In order
  to guarantee determinism, though, deterministic-by-construction
  models must sharply restrict the sharing of memory between parallel
  tasks: shared memory, if it is allowed at all, is typically limited
  either to single-assignment locations, or to a single type of shared
  data structure, such as a blocking FIFO queue.

  This thesis will show that \emph{lattice-based data structures}, or
  \emph{LVars}, enable an expressive and useful style of
  deterministic-by-construction parallel programming that generalizes
  and unifies previously existing approaches.  LVars generalize
  existing single-assignment models to allow multiple assignments that
  are monotonically increasing with respect to an application-specific
  lattice.  LVars ensure determinism by allowing only monotonic writes
  and ``threshold'' reads that block until a lower bound is reached
  and do not allow the order in which information is added to the LVar
  to be observed.  After presenting the basic LVars model and showing
  that it is deterministic, I will show how to extend it to allow
  non-blocking ``freezing'' reads, resulting in a
  \emph{quasi-deterministic} model in which programs are guaranteed to
  behave deterministically modulo exceptions, and \emph{event
    handlers}, which enable an expressive and useful style of
  deterministic or quasi-deterministic programming.

  Next, I will demonstrate the viability of the LVars approach with
  \emph{LVish}, a Haskell library based on the LVars model.  LVish
  provides a monad in which LVar computations run; it leverages
  Haskell's type system to index such computations with an effect
  level to ensure that only certain LVar effects can occur in a given
  computation, hence statically enforcing determinism or
  quasi-determinism.  I will illustrate the LVish programming model
  with examples and present results from several case studies that
  demonstrate the applicability of LVish.

  Finally, I will investigate the relationship between LVars and
  \emph{conflict-free replicated data types} (CRDTs), which are data
  structures for reasoning about and enforcing the eventual
  consistency of replicated objects in a distributed system.  In one
  direction, I will investigate extending CRDTs to support LVar-style
  threshold reads.  Threshold reads will guarantee that the order in
  which information is added to a CRDT cannot be observed, ensuring a
  greater degree of consistency (at the price of read availability).
  In the other direction, I will use techniques from the CRDT
  literature to implement LVar-based data structures that support
  non-monotonic updates: PN-Counters, which can be decremented as well
  as incremented, and OR-Sets, from which elements can be removed as
  well as added.
\end{abstract}

\section{Introduction}

\section{Deterministic-by-construction parallel programming}

Parallel programming is notoriously difficult.  \lk{Difficult to who?}
A fundamental reason for this notoriety is that programs can yield
inconsistent results, or even crash, due to unpredictable interactions
between parallel tasks.  But it doesn't have to be this way:
\emph{deterministic-by-construction} parallel programming models offer
the promise of freedom from subtle, hard-to-reproduce nondeterministic
bugs in parallel code.

A deterministic-by-construction programming model is one that ensures
that all programs written using the model have the same
\emph{observable behavior} every time they are run.  What does
``observable behavior'' mean?  There are many ways to define what is
observable about a program.  Clearly, we do \emph{not} wish to
preserve behaviors such as running time across multiple
runs---ideally, a deterministic-by-construction parallel program will
run faster when more parallel resources are available!  In this
proposal, we define the observable behavior of a program to be the
value to which it evaluates.  Specifically, we do not count the
behavior of the scheduler as observable.  Indeed, the purpose of our
deterministic-by-construction model will be to allow tasks to be
scheduled dynamically and unpredictably, without allowing such
\emph{schedule nondeterminism} to affect programs' observable
behavior.

\section{Existing approaches to determinism by construction}

Shared state between computations allows the possibility for
\emph{data races} that allow schedule nondeterminism to be
observed---if one thread writes $3$ to a shared location while another
writes $4$, then another thread that reads and returns the value will
nondeterministically return $3$ or $4$ depending on how the threads
are scheduled to run.  Therefore, deterministic parallel programming
models necessarily limit sharing of mutable state between parallel
tasks.


Introduce the problem.

Explain, at a high level, what my work does to solve the problem.

Explain what the structure of this proposal will be.

This citation \cite{LVars-TR} is here to make LaTeX happy.

\section{Background}

\section{Thesis statement}

\lk{This format ripped off from Josh Dunfield.}

With the above background, I can state my thesis:

\lk{``novel, feasible and useful''}

\lk{ ``Lattice-based data structures, whose contents grow
  monotonically with respect to an application-specific lattice and
  for which the order in which information is added is not observable,
  are a novel, feasible, and useful means of guaranteeing the
  determinism of parallel programs.''  This isn't right.  It's not
  ``here's a parallel program, let's apply lattice-based data
  structures to it and guarantee its determinism that way!''  It's,
  ``Let's build lattice-based data structures into the programming
  model to start.''  }

\begin{quote}
  Lattice-based data structures\lk{, whose contents grow monotonically
  with respect to an application-specific lattice and for which the
  order in which information is added is not observable,} are a
  practical, flexible, and mathematically rigorous foundation for
  deterministic parallel and distributed programming.
\end{quote}

\lk{Better...I'm still unsure about ``and distributed''.}

\section{Technical overview}

\section{Freezing, handlers, and quasideterminism}

\section{LVars and CRDTs}

In this section, I will discuss the relationship between the LVars
model I've described and the mathematical framework of
\emph{conflict-free replicated data types} that distributed systems
research have developed for reasoning about and enforcing the eventual
consistency of distributed replicated objects.

\subsection{Replication and eventual consistency}

Distributed systems often involve \emph{replication} of data objects
across a number of physical locations.  Reasons to replicate data may
include:
\begin{itemize}
\item Robustness to failure: if multiple replicas of an object exist,
  we are less likely to lose that object if part of our system fails.

\item Proximity: objects should be close to clients who need them.

\item Parallelism: different processes simultaneously operating on the
  same object may each need their own copy. \lk{Explain how this is
    different from the above point.}
\end{itemize}
If a system of distributed, replicated objects behaved
indistinguishably from the model a lot of us are used to programming
with, in which all our data and all our computation are on one
machine, then we would not need to concern ourselves with special
techniques to support replication.  \lk{This is worded awkwardly ---
  look at the CRDT papers for inspiration?}  Unfortunately, this is
not the case.

\section{Related work}

\paragraph{Concurrent Revisions}

The Concurrent Revisions (CR)~\cite{concurrent-revisions-haskell11}
programming model uses \emph{isolation types} \cite{isolation-types}
to distinguish regions of the heap shared by multiple mutators.
Rather than enforcing exclusive access in the style of DPJ, CR clones
a copy of the state for each mutator, using a deterministic ``merge
function'' for resolving conflicts in local copies at join points.

Variables can be annotated as being shared between a ``joiner'' thread
and a ``joinee'' thread.  Unlike the least-upper-bound writes of
LVars, CR merge functions are \emph{not} necessarily commutative;
indeed, the default CR merge function is ``joiner wins''.  Determinism
is enforced by the programming model allowing the programmer to
specify which of two writing threads should prevail, regardless of the
order in which those writes arrive.  Hence the states that such a
shared variable take on need not form a lattice.

Still, semilattices turn up in the metatheory of CR: in particular,
Burckhardt and Leijen~\cite{semantics-concurrent-revisions} show that,
for any two vertices in a CR revision diagram, there exists a
\emph{greatest common ancestor} state which can be used to determine
what changes each side has made---an interesting duality with our
model (in which any two LVar states have a lub). \lk{TODO: Write to
  them and ask them if it's a join-semilattice or a meet-semilattice!}

If versioned variables used least upper bound as their merge function
for conflicts\lk{TODO: see if ``versioned variables'' is the term they
  use}, the CR programming model would match that of LVars.  \lk{Think
  of a better way to word that last part.}  But it nevertheless
differs from the LVars model in that, in CR, effects only become
visible at the end of parallel regions. \lk{Check that this is true.}
This precludes the use of traditional lock-free data structures as a
representation for versioned variables.  LVars, on the other hand,
allow asynchronous communication within parallel regions.

\section{Road map}

I have already completed substantial work towards my thesis:

\begin{itemize}
\item \lk{Some stuff about original LVars paper}
\item \lk{Some stuff about Freeze paper}
\end{itemize}
To complete the thesis, I plan to do the following:
\begin{itemize}
\item \lk{Some stuff about CRDTs and LVars.}
\item \lk{Write the dissertation.}
\end{itemize}
\lk{Time estimates to be added.}

\bibliographystyle{plain}
\bibliography{../latex_common/refs}

\end{document}
