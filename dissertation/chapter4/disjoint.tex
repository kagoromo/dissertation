\section{\il{Par}-monad transformers and disjoint parallel update}\label{s:lvish-disjoint}

The effect-tracking system of the previous section provides a way to
toggle on and off a fixed set of basic capabilities, such as @HasPut@,
using the type system---that is, with the effect level @e@ that
parameterizes the @Par@ type.  However, it does not give us a way to
add new, unanticipated capabilities to a @Par@ computation.  For that,
we turn to \emph{monad transformers}.

In Haskell, a monad transformer is a type constructor that adds
``plug-in'' capabilities to an underlying monad.  For example, the
@StateT@ monad transformer adds an extra piece of implicit, modifiable
state to an underlying monad.  Adding a monad transformer to a type
always returns another monad (preserving the @Monad@ instance).  We
can therefore define a \emph{\il{Par}-monad transformer} as a type
constructor @T@ where, for all @Par@ monads @m@, @T m@ is another
@Par@ monad with additional capabilities, and where a value of type
@T m a@, for instance, @T (Par e s) a@, is a computation in that monad.

\subsection{Example: threading state in parallel}

We can use the standard @StateT@ monad transformer (provided by
Haskell's @Control.Monad.State@ package) as a @Par@-monad transformer.
However, even if @m@ is a @Par@ monad, for @StateT s m@ to also be a
@Par@ monad, the state @s@ must be \emph{splittable}; that is, it must
be specified what is to be done with the state at @fork@ points in the
control flow.  For example, the state may be duplicated, split, or
otherwise updated to note the fork.

The below code promotes @StateT@ to be a @Par@-monad transformer:

\singlespacing
\begin{lstlisting}
class SplittableState a where
  splitState :: a -> (a, a)

instance (SplittableState s, ParMonad m) => 
         ParMonad (StateT s m) where  
  fork task =
     do s <- oState.get 
        let (s1, s2) = splitState s
        State.put s2
        lift (fork (do runStateT task s1; return ()))
\end{lstlisting}
\doublespacing

\lk{An aside: this code reflects what appeared in our PLDI '14
  ``Effect Zoo'' paper, but it doesn't actually reflect how things are
  done in the LVish library of 2015; ParST no longer uses StateT.
  However, how ParST is implemented is really just an implementation
  detail.  As Ryan puts it: ``It happens that when Omer and I were
  overhauling it during one of our pair programming sessions, we
  reimplemented StateT ourselves (it's a trivial monad), initially
  because ParMonad's p and Monad's m now look different.  Later, we
  figured out that we could still use StateT if we wanted, but it's
  not important.  The important thing for ParST should be what API is
  exposed to the user.''}

Note that here, @put@ and @get@ are not LVar operations, but the
standard operations for setting and retrieving the state in a
@StateT@.

\subsection{Determinism guarantee}

The @StateT@ transformer preserves determinism because it is
effectively \emph{syntactic sugar}.  That is, @StateT@ does not allow
one to write any program that could not already be written using the
underlying @Par@ monad, simply by passing around an extra argument.
This is because @StateT@ only provides a \emph{functional} state (an
implicit argument and return value), not actual mutable heap
locations.  Genuine mutable locations in pure computations, on the
other hand, require Haskell's @ST@ monad, the safer sister monad to
@IO@.

\subsection{Disjoint parallel update with \il{ParST}}

The LVars model is based on the notion that it is fine for multiple
threads to access and update shared memory, so long as updates commute
and ``build on'' one another, only adding information rather than
destroying it.  But it should also be possible for threads to update
memory destructively, so long as the memory updated by different
threads is \emph{disjoint}.  This is the approach to deterministic
parallelism taken by, for example, Deterministic Parallel Java
(DPJ)~\cite{dpj-oopsla}, which uses a region-based type and effect
system to ensure that each mutable region of the heap is passed
linearly to a thread that then gains exclusive permission to update
that region.

In order to add this capability to the LVish library, we need
destructive updates to interoperate with LVar effects.  Moreover, we
wish to do so at the library level, without requiring language
extensions.  Our solution is to provide a monad called @ParST@ that
uses the @StateT@ transformer described above to layer additional
mutable state on top of the existing capabilities of the LVish @Par@
monad.  @ParST@ allows arbitrarily complex mutable state, such as
tuples of vectors (arrays).  However, @ParST@ enforces the restriction
that every memory location in the state is reachable by only one
pointer: alias freedom.

Previous approaches to integrating mutable memory with pure functional
code (\ie, the @ST@ monad) work with LVish, but only allow
thread-private memory.  There is no way to operate on the same
structure (for instance, on two halves of an array) from different
threads.  @ParST@ exploits the fact that that simultaneous access from
different threads can be deterministic, as long as the threads are
accessing disjoint parts of the data structure.
Listing~\ref{listing-disjoint-parallel-update} illustrates the idea
using @ParVecT@, which is a specialized variant of @ParST@ that
supports a particular kind of shared state: a single mutable vector.

\singlespacing \lstinputlisting[float, caption={A program illustrating
    disjoint parallel update inside an LVar computation.},
  label=listing-disjoint-parallel-update]{chapter4/code/disjoint-parallel-update.hs}
\doublespacing

The code in Listing~\ref{listing-disjoint-parallel-update} writes to
each element in a six-element vector, then splits the vector into two
parts and updates each part in parallel.  (The first argument to
@runParVecT@, in this case @6@, specifies the length of the vector.)
The call to @forkSTSplit@ forks the control flow of the program, and
@(write 0 "bar")@ and @(write 0 "baz")@ are the two forked child
computations.  @forkSTSplit@ takes as its first argument a ``split
point'', which is the index at which the vector is to be split.  Here,
that index is @3@, which means that the first child computation passed
to @forkSTSplit@ may access only the first half of the vector, while
the other may access only the second half.  Each child computation
sees only a \emph{local} view of the vector, so writing @"bar"@ to
index @0@ in the second child computation is really writing to index
@3@ of the full vector.

The call to @freeze@ in in
Listing~\ref{listing-disjoint-parallel-update} is not to be confused
with an LVar freeze operation; it is instead the @freeze@ operation
from the @Data.Vector@ library which produces an immutable copy of a
mutable vector.  In the last line of
Listing~\ref{listing-disjoint-parallel-update}, calling @runParVecT@
discharges the extra state effect that @ParVecT@ provides, leaving the
underlying @Par@ computation, which is then run with @runPar@.  In
this example, printing the result of the @runPar@ gives us
@["bar","foo","foo","baz","foo","foo"]@.

Ensuring the determinism of @ParST@ hinges on two requirements:

\begin{itemize}
\item \emph{Disjointness:} Any thread can get a direct pointer to its
  state.  In Listing~\ref{listing-disjoint-parallel-update}, @ptr@ is
  an @STVector@ that can be passed to any standard library procedures
  in the @ST@ monad.  However, it must \emph{not} be possible to
  access @ptr@ from @forkSTSplit@'s child computations.  We accomplish
  this using Haskell's support for higher-rank types,\footnote{That
    is, the type of a child computation begins with \il{(forall s .
      ParST ...)}.} ensuring that accessing @ptr@ from a child
  computation causes a type error.  Finally, @forkSTSplit@ is a
  fork-join construct; after it completes, the parent thread again has
  full access to @ptr@.

\item \emph{Alias freedom:} Imagine that we expanded the example in
  Listing~\ref{listing-disjoint-parallel-update} to have as its state
  a \emph{tuple} of two vectors $(v_1, v_2)$.  If we allowed the
  programmer to supply an arbitrary initial state to the @ParST@
  computation, then they might provide the state $(v_1, v_1)$, \ie,
  two copies of the same pointer.  This breaks the abstraction,
  enabling them to reach the same mutable location from multiple
  threads (by splitting the supposedly-disjoint vectors at a different
  index).  Thus, in LVish, users do not populate the state directly,
  but only describe a \emph{recipe} for its creation.  Each type used
  as a @ParST@ state has an associated type for descriptions of (1)
  how to create an initial structure, and (2) how to split it into
  disjoint pieces.  LVish provides a library of instances for commonly
  used types.
\end{itemize}

\subsection{Inter-thread communication}

Disjoint state update does not solve the problem of communication
between threads.  Hence systems built around this idea often include
other means for performing reductions, or require ''commutativity
annotations'' for operations such as adding to a set.  For instance,
DPJ provides a @commuteswith@ form for asserting that operations
commute with one another to enable concurrent mutation.  In LVish,
however, such annotations are unnecessary, because LVish already
provides a language-level guarantee that all effects commute!  Thus, a
programmer using LVish with @ParST@ can use any LVar to communicate
results between threads performing disjoint updates, without requiring
trusted code or annotations.  Moreover, LVish with @ParST@ is unique
among deterministic parallel programming models in that it allows both
DPJ-style, disjoint destructive parallel updates, and blocking,
dataflow-style communication between threads (through LVars).
