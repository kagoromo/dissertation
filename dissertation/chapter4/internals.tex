\section{The LVish library implementation}\label{s:lvish-internals}

\lk{In our POPL paper, we discussed the importance of idempotence at
  the start of the implementation section.  However, it seems to me
  that it should be de-emphasized here.  I make a big enough deal of
  being able to support arbitrary update operations (which aren't
  idempotent) that it seems disingenuous to make a big thing out of
  idempotence here.  (Also, increment-only counters (which were the
  whole motivation for generalizing \il{put} in the first place)
  aren't atomistic, either!  But at least the ``Leveraging atoms''
  stuff doesn't \emph{require} lattices to be atomistic.)  Also, the
  material on \il{putLV} probably needs to be significantly revised
  and updated to be able to account for non-idempotent writes.}
\rn{I totally agree.}

In this section, \either{I}{we} describe the internals of the LVish library,
including how the library represents LVars and @Par@ computations
internally and how it implements lattice-generic functions for
writing, reading, and freezing LVars, as well as registering handlers
and quiescing LVars.  First, though, \either{I}{we} discuss a semantic
observation about lattices that our implementation makes use of.

\subsection{Leveraging atoms}\label{subsection:lvish-leveraging-atoms}

Monotonic data structures acquire ``pieces of information'' over time.
In a lattice, the smallest such pieces are called the \emph{atoms} of
the lattice: they are elements not equal to $\bot$, but for which the
only smaller element is $\bot$.  Lattices for which every element is
the lub of some set of atoms are called \emph{atomistic}, and in
practice most lattices used by LVish programs
have this property---especially those that represent
collections.

In general, the LVish primitives allow arbitrarily large queries and
updates to an LVar.  But for an atomistic lattice, the corresponding
data structure usually exposes operations that work at the atom level,
semantically limiting writes to atoms, @get@s to threshold sets of
atoms, and event sets to sets of atoms.  For example, the lattice of
finite maps is atomistic, with atoms consisting of all singleton maps
(\ie, all key/value pairs).  The interface to a finite map usually
works at the atom level, allowing addition of a new key/value pair,
querying of a single key, or traversals (which we model as handlers)
that walk over one key/value pair at a time.

Our implementation is designed to facilitate good performance for
atomistic lattices by associating LVars with a set of \emph{deltas}
(changes), as well as a lattice.  For atomistic lattices, the deltas
are essentially just the atoms---for a set lattice, a delta is an
element; for a map, a key/value pair.  Deltas provide a compact way to
represent a change to the lattice, allowing us to easily and
efficiently communicate such changes between writes and
@get@s/handlers.

\lk{Someone who is more familiar with the current state of LVish than
  I am should audit the next few sections and make sure it's still
  accurate.}

\subsection{Representation choices}

LVish uses the following generic representation for LVars:

\singlespacing
\begin{lstlisting}
  data LVar a d = 
       LVar { state :: a,  status :: IORef (Status d) }
\end{lstlisting}
\doublespacing

where the type parameter @a@ is the (mutable) data structure
representing the lattice, and @d@ is the type of deltas for the
lattice.\footnote{For non-atomistic lattices, we take \il{a} and
  \il{d} to be the same type.}  The @status@ field is a mutable
reference that represents the status bit, which says whether or not an
LVar is frozen:

\singlespacing
\begin{lstlisting}
  data Status d = Frozen | Active (B.Bag (Listener d))
\end{lstlisting}
\doublespacing

The status bit of an LVar is tied together with a bag of waiting
\emph{listeners}, which include blocked @get@s and handlers; once the
LVar is frozen, there can be no further events to listen
for.\footnote{In particular, with one atomic update of the flag we
  both mark the LVar as frozen and allow the bag to be
  garbage-collected.}  The bag module (imported as @B@) supports
atomic insertion and removal, and \emph{concurrent} traversal:

\singlespacing
\begin{lstlisting}
  put     :: Bag a -> a -> IO (Token a)
  remove  :: Token a -> IO ()
  foreach :: Bag a -> (a -> Token a -> IO ()) -> IO ()
\end{lstlisting}
\doublespacing

Removal of elements is done via abstract \emph{tokens}, which are
acquired by insertion or traversal.  Updates may occur concurrently
with a traversal, but are not guaranteed to be visible to it.

A listener for an LVar is a pair of callbacks, one called when the
LVar's lattice value changes, and the other when the LVar is frozen:

\singlespacing
\begin{lstlisting}
 data Listener d = Listener {
   onUpd :: d -> Token (Listener d) -> SchedQ -> IO (),
   onFrz ::      Token (Listener d) -> SchedQ -> IO () }
\end{lstlisting}
\doublespacing

The listener is given access to its own token in the listener bag,
which it can use to deregister from future events (useful for a @get@
whose threshold has been passed).  It is also given access to the
CPU-local scheduler queue, which it can use to spawn threads.

Internally, the @Par@ monad represents computations in
continuation-passing style, in terms of their interpretation in the
@IO@ monad:

\singlespacing
\begin{lstlisting}
  type ClosedPar = SchedQ -> IO ()
  type ParCont a = a -> ClosedPar
  mkPar :: (ParCont a -> ClosedPar) -> Par lvl a
\end{lstlisting}
\doublespacing

The @ClosedPar@ type represents ready-to-run @Par@ computations, which
are given direct access to the CPU-local scheduler queue.  Rather than
returning a final result, a completed @ClosedPar@ computation must
call the scheduler, @sched@, on the queue.  A @Par@ computation, on
the other hand, completes by passing its intended result to its
continuation---yielding a @ClosedPar@ computation.

\subsection{Threshold reading}

\begin{figure}
  \singlespacing
  \lstinputlisting{chapter4/code/getLV.hs}
  \doublespacing
  \caption{Implementation of the \il{getLV}
    function.}\label{fig:implementation-getLV}
\end{figure}

Figure~\ref{fig:implementation-getLV} gives the implementation for the
lattice-generic @getLV@ function, which assists data structure authors
in writing operations with @get@ semantics.  In addition to an LVar,
it takes two \emph{threshold functions} as arguments, one for global
state and one for deltas.\footnote{In this sense, the way that
  threshold reads are implemented in LVish of is in fact quite close
  to the semantic notion of \emph{threshold functions} that \either{I}{we}
  described in
  Section~\ref{subsection:lvars-generalizing-from-threshold-sets-to-threshold-functions}.}
The \emph{global threshold} @gThresh@ is used to initially check
whether the LVar is above some lattice value(s) by global inspection;
the extra boolean argument gives the frozen status of the LVar.  The
\emph{delta threshold} @dThresh@ checks whether a particular update
takes the state of the LVar above some lattice state(s).  Both
functions return @Just r@ if the threshold has been passed, where @r@
is the result of the read.  To continue our running example of finite
maps with key/value pair deltas, we can use @getLV@ internally to
build the following @getKey@ function that is exposed to application
writers:

\singlespacing
\begin{lstlisting}
  -- Wait for the map to contain a key; return its value
  getKey key mapLV = getLV mapLV gThresh dThresh where
    gThresh m frozen = lookup key m
    dThresh (k,v) | k == key  = return (Just v)
                  | otherwise = return Nothing 
\end{lstlisting}
\doublespacing

where @lookup@ imperatively looks up a key in the underlying map.

The challenge in implementing @getLV@ is the possibility that a
\emph{concurrent} write will push the LVar over the threshold.  To
cope with such races, @getLV@ employs a somewhat pessimistic strategy:
before doing anything else, it enrolls a listener on the LVar that
will be triggered on any subsequent updates.  If an update passes the
delta threshold, the listener is removed, and the continuation of the
@get@ is invoked, with the result, in a new lightweight thread.
\emph{After} enrolling the listener, @getLV@ checks the \emph{global}
threshold, in case the LVar is already above the threshold.  If it is,
the listener is removed, and the continuation is launched immediately;
otherwise, @getLV@ invokes the scheduler, effectively treating its
continuation as a blocked thread.

By doing the global check only after enrolling a listener, @getLV@ is
sure not to miss any threshold-passing updates.  It does \emph{not}
need to synchronize between the delta and global thresholds: if the
threshold is passed just as @getLV@ runs, it might launch the
continuation twice (once via the global check, once via delta), \textred{but by
idempotence this does no harm.}  This is a performance tradeoff: we
avoid imposing extra synchronization on \emph{all} uses of @getLV@ at
the cost of some duplicated work in a rare case.  We can easily
provide a second version of @getLV@ that makes the alternative
tradeoff, but as we will see below, idempotence plays an
\emph{essential} role in the analogous situation for handlers.

\subsection{Putting and freezing}

\TODO{I think this section needs to be updated to accommodate
  non-idempotent writes, but I need some help in figuring out what to
  say.}

\begin{figure}
  \singlespacing
  \lstinputlisting{chapter4/code/putLV.hs}
  \doublespacing
  \caption{Implementation of the \il{putLV}
    function.}\label{fig:implementation-putLV}
\end{figure}

\begin{figure}
  \singlespacing
  \lstinputlisting{chapter4/code/freezeLV.hs}
  \doublespacing
  \caption{Implementation of the \il{freezeLV}
    function.}\label{fig:implementation-freezeLV}
\end{figure}

Figures~\ref{fig:implementation-putLV}
and~\ref{fig:implementation-freezeLV} respectively give the
implementations for the lattice-generic @putLV@ and @freezeLV@
functions.  The @putLV@ function is used to build operations with
@put@ semantics.  It takes an LVar and an \emph{update function}
@doPut@ that performs the @put@ on the underlying data structure,
returning a delta if the @put@ actually changed the data structure.
If there is such a delta, @putLV@ subsequently invokes all
currently-enrolled listeners on it.

The implementation of @putLV@ is complicated by another race, this
time with freezing.  If the @put@ is nontrivial (\ie, if it changes
the value of the LVar), the race can be resolved in two ways.  Either
the freeze takes effect first, in which case the @put@ must fault, or
else the @put@ takes effect first, in which case both succeed.
Unfortunately, we have no means to both check the frozen status
\emph{and} attempt an update in a single atomic step.\footnote{While
  we could require the underlying data structure to support such
  transactions, doing so would preclude the use of existing lock-free
  data structures, which tend to use a single-word compare-and-set
  operation to perform atomic updates.  Lock-free data structures
  routinely outperform transaction-based data
  structures~\cite{practical-lock-freedom}.}

Our basic approach is to ask forgiveness, rather than permission: we
eagerly perform the @put@, and only afterwards check whether the LVar
is frozen.  Intuitively, this is allowed because \emph{if} the LVar is
frozen, the @Par@ computation is going to terminate with an
exception---so the effect of the @put@ cannot be observed!

Unfortunately, it is not enough to \emph{just} check the status bit
for frozenness afterward, for a rather subtle reason: suppose the
@put@ is executing concurrently with a @get@ which it causes to
unblock, and that the @get@ting thread subsequently freezes the LVar.
In this case, we \emph{must} treat the @freeze@ as if it happened
after the @put@, because the @freeze@ could not have occurred had it
not been for the @put@. But, by the time @putLV@ reads the status bit,
it may already be set, which naively would cause @putLV@ to fault.

To guarantee that such confusion cannot occur, we add a \emph{marked}
bit to each CPU scheduler state.  The bit is set (using @Sched.mark@)
prior to a @put@ being performed, and cleared (using @Sched.clear@)
only \emph{after} @putLV@ has subsequently checked the frozen status.
On the other hand, @freezeLV@ waits until it has observed a
(transient!) clear mark bit on every CPU (using @Sched.awaitClear@)
before actually freezing the LVar.  This guarantees that any @put@s
that \emph{caused} the freeze to take place check the frozen status
\emph{before} the freeze takes place; additional @put@s that arrive
concurrently may, of course, set a mark bit again after @freezeLV@ has
observed a clear status.

The proposed approach requires no barriers or synchronization
instructions (assuming that the @put@ on the underlying data structure
acts as a memory barrier).  Since the mark bits are per-CPU flags,
they can generally be held in a core-local cache line in exclusive
mode---meaning that marking and clearing them is extremely cheap.  The
only time that the busy flags can create cross-core communication is
during @freezeLV@, which should only occur once per LVar computation.

One final point: unlike @getLV@ and @putLV@, which can be used in deterministic
contexts, a computation that performs @freezeLV@ is necessarily
quasi-deterministic or non-deterministic.

\subsection{Handlers, pools and quiescence}

Given the above infrastructure, the implementation of handlers is
relatively straightforward.  We represent handler pools as follows:

\singlespacing
\begin{lstlisting}
  data HandlerPool = HandlerPool {
    numCallbacks :: Counter,  blocked :: B.Bag ClosedPar }
\end{lstlisting}
\doublespacing

where @Counter@ is a simple counter supporting atomic increment,
decrement, and checks for equality with zero.\footnote{One can use a
  high-performance \emph{scalable non-zero indicator}~\cite{snzi} to
  implement \il{Counter}, but we have not yet done so.}  We use the
counter to track the number of currently-executing callbacks, which we
can use to implement @quiesce@.  A handler pool also keeps a bag of
threads that are blocked waiting for the pool to reach a quiescent
state.

We create a pool using @newPool@ (of type @Par lvl HandlerPool@), and
implement quiescence testing as follows:

\singlespacing
\begin{lstlisting}
  quiesce :: HandlerPool -> Par lvl ()
  quiesce hp@(HandlerPool cnt bag) = mkPar $ \k q -> do
    tok <- B.put bag (k ())
    quiescent <- poll cnt
    if quiescent then do B.remove tok; k () q
                 else sched q
\end{lstlisting}
\doublespacing

where the @poll@ function indicates whether @cnt@ is (transiently)
zero.  Note that we are following the same listener-enrollment
strategy as in @getLV@, but with @blocked@ acting as the bag of
listeners.

Finally, @addHandler@ has the following interface:

\singlespacing
\begin{lstlisting}
addHandler :: 
     Maybe HandlerPool              -- Pool to enroll in
  -> LVar a d                       -- LVar to listen to
  -> (a -> IO (Maybe (Par lvl ()))) -- Global callback
  -> (d -> IO (Maybe (Par lvl ()))) -- Delta callback
  -> Par lvl ()
\end{lstlisting}
\doublespacing

As with @getLV@, handlers are specified using both global and delta
threshold functions.  Rather than returning results, however, these
threshold functions return computations to run in a fresh lightweight
thread if the threshold has been passed.  Each time a callback is
launched, the callback count is incremented; when it is finished, the
count is decremented, and if zero, all threads blocked on its
quiescence are resumed.

\subsection{Discussion: leveraging idempotency}\label{subsection:lvish-discussion-leveraging-idempotency}

While \either{I}{we} have emphasized the commutativity of the lub operation, it
also has another important property: \emph{idempotence}, meaning that
$\userlub{d}{d} = d$ for any element $d$.  In LVar terms, repeated
@put@s or @freeze@s have no effect, and so, in an LVish program that
restricts itself to @put@s (instead of arbitrary update operations,
which are not necessarily idempotent), the result is that $e; e$
behaves the same as $e$ for any LVish expression $e$.

Idempotence has already been recognized as a useful property for
work-stealing scheduling~\cite{idempotent}: if the scheduler is
allowed to occasionally duplicate work, it is possible to
substantially save on synchronization costs.  For LVish computations
that are guaranteed to be idempotent, we could use such a scheduler
(although the existing implementation uses the standard Chase-Lev
deque~\cite{ChaseLev}).

Moreover, idempotence also helps us deal with races between writes and
calls to @addHandler@.  The implementation of @addHandler@ is very
similar to @getLV@, but there is one important difference: handler
callbacks must be invoked for \emph{all} events of interest, not just
a single threshold.  Thus, the @Par@ computation returned by the
global threshold function should execute its callback on, \eg, all
available atoms.  Likewise, we do not remove a handler from the bag of
listeners when a single delta threshold is passed; handlers listen
continuously to an LVar until it is frozen.  We might, for example,
expose the following @foreach@ function for a finite map:

\singlespacing
\begin{lstlisting}
 foreach mh mapLV cb = addHandler mh lv gThresh dThresh
   where
     dThresh (k,v) = return (Just (cb k v))
     gThresh mp    = traverse mp (\(k,v) -> cb k v) mp
\end{lstlisting}
\doublespacing

Here, idempotence really pays off: without it, we must synchronize to
ensure that no callbacks are duplicated between the global threshold
(which may or may not see concurrent additions to the map) and the
delta threshold (which will catch all concurrent additions).

Naturally, it is best to pay the aforementioned synchronization
overhead only when required.  This requires static information about
whether a given program uses non-idempotent writes.  Fortunately,
LVish's fine-grained effect-tracking capability can provide precisely
this information.  We refer to a write that is specifically
non-idempotent as a \emph{bump}, and the @HasBump@ effect level
constraint says that a @Par@ computation is allowed to perform such
writes.  For example, an increment-only counter might have an
@incrCounter@ operation with the following signature:

\singlespacing
\begin{lstlisting}
   incrCounter :: HasBump e => Counter s -> Par s e ()
\end{lstlisting}
\doublespacing

\lk{This is from the PLDI paper, but shouldn't it also have \il{NoPut}
  as a constraint?}

\lk{There should really be more in this section about how the
  information provided by \il{HasBump} or \il{NoBump}, etc., is
  actually communicated to and used by the runtime system.  But I
  don't actually know how that works! :( Ryan and Aaron, I need your
  help here.}
