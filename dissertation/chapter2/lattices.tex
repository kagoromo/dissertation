\section{Lattices, stores, and determinism}\label{s:lvars-lattices}

As a minimal substrate for LVars, \either{I}{we} introduce $\lambdaLVar$, a
parallel call-by-value $\lambda$-calculus extended with a \emph{store}
and with communication primitives @put@ and @get@ that operate on data
in the store.  The class of programs that \either{I am}{we are} interested in modeling
with $\lambdaLVar$ are those with explicit effectful operations on
shared data structures, in which parallel subcomputations may
communicate with each other via the @put@ and @get@ operations.

In $\lambdaLVar$, stores contain LVars.  Whereas IVars are
single-assignment variables---either empty
or filled with an immutable value---an LVar may have an arbitrary
number of states forming a set $D$, which is partially ordered by a
relation $\userleq$.  An LVar can take on any sequence of states from
$D$, so long as that sequence respects the partial order---that is, so
long as updates to the LVar (made via the @put@ operation) are
\emph{inflationary} with respect to $\userleq$.  Moreover, the @get@
operation allows only limited observations of the LVar's state.  In
this section, \either{I}{we} discuss how lattices and stores work in $\lambdaLVar$
and explain how the semantics of @put@ and @get@ together enforce
determinism in $\lambdaLVar$ programs.

\subsection{Lattices}\label{subsection:lvars-lattices}

The definition of $\lambdaLVar$ is parameterized by $D$: to write
concrete $\lambdaLVar$ programs, we must specify the set of LVar
states that we are interested in working with, and an ordering on
those states.  Therefore $\lambdaLVar$ is actually a \emph{family} of
languages, rather than a single language.

Formally, $D$ is a \emph{bounded join-semilattice} augmented with a
greatest element $\top$.  That is, $D$ has the following structure:
\begin{itemize}
\item $D$ has a least element $\bot$, representing the initial
  ``empty'' state of an LVar.
\item $D$ has a greatest element $\top$, representing the ``error''
  state that results from conflicting updates to an LVar.
\item $D$ comes equipped with a partial order $\userleq$, where $\bot
  \userleq d \userleq \top$ for all $d \in D$.
\item Every pair of elements in $D$ has a lub, written $\sqcup$.
  Intuitively, the existence of a lub for every two elements in $D$
  means that it is possible for two subcomputations to independently
  update an LVar, and then deterministically merge the results by
  taking the lub of the resulting two states.
\end{itemize}
We can specify all these components as a 4-tuple $(D, \userleq, \bot,
\top)$ where $D$ is a set, $\userleq$ is a partial order on the
elements of $D$, $\bot$ is the least element of $D$ according to
$\userleq$, and $\top$ is the greatest element.  However, \either{I}{we} use $D$ as a
shorthand for the entire 4-tuple $(D, \userleq, \bot, \top)$ when its
meaning is clear from the context.
\ifdefined\JOURNAL
For brevity, we also use the term
``lattice'' in place of ``bounded join-semilattice with a designated
greatest element'' throughout this paper.
\fi

Virtually any data structure to which information is added gradually
can be represented as a lattice, including pairs, arrays, trees, maps,
and infinite streams.  In the case of maps or sets, $\sqcup$ could be
defined as union; for pointer-based data structures like tries, $\sqcup$
could allow for unification of partially-initialized structures.

The simplest example of a useful $D$ is one that represents the
states that a single-assignment variable (that is, an IVar) can take
on.  The states of a natural-number-valued IVar, for instance, are the elements of
the lattice in
Figure~\ref{f:lvars-example-lattices}(b), that is,

\vspace{-8mm}
\singlespacing
\begin{displaymath}
  D = (\lbrace \top, \bot \rbrace \cup \mathbb{N}, \userleq, \bot, \top), 
\end{displaymath}
\doublespacing

where the partial order $\userleq$ is defined by setting $\bot
\userleq d \userleq \top$ and $d \userleq d$ for all $d \in D$.  This
is a lattice of height three and infinite width, where the naturals
are arranged horizontally.  After the initial write of some $n \in
\mathbb{N}$, any further conflicting writes would push the state of
the IVar to $\top$ (an error).  For instance, if one thread writes $2$
and another writes $1$ to an IVar (in arbitrary order), the second of
the two writes would result in an error because $2 \sqcup 1 = \top$.

In the lattice of Figure~\ref{f:lvars-example-lattices}(a), on the
other hand, the $\top$ state is unreachable unless $\top$ is
explicitly written to the LVar, because the lub of any two writes is
just the maximum of the two.  If one thread writes $2$ and another
writes $1$, the resulting state will be $2$, since $2 \sqcup 1 = 2$.

\ifdefined\DISSERTATION
\begin{wrapfigure}{r}{2.3in}
\vspace{-2em}
\begin{center}
  \includegraphics[scale=0.15]{../illustrations/store}
\end{center}
\vspace{-2em}
\end{wrapfigure}
\fi

\subsection{Stores}\label{subsection:lvars-stores}

During the evaluation of a $\lambdaLVar$ program, a \emph{store} $S$
keeps track of the states of LVars.  Each LVar is represented by a
\emph{binding} that maps a location $l$, drawn from a countably infinite
set $\Loc$, to a \emph{state}, which is some element $d \in D$.
Although each LVar in a program has its own state, the states of all
the LVars are drawn from the same lattice $D$.\footnote{In practice,
  different LVars in a program might correspond to different lattices (and,
  in the LVish Haskell library that \either{I}{we} will present in
  \either{Chapter}{Section}~\ref{ch:lvish}, they do).  Multiple lattices can in
  principle be encoded using a sum construction, so this modeling
  choice is just to keep the presentation simple.}

\LVarsDefStore

\either{I}{We} use the notation $\extSRaw{S}{l}{d}$ to denote extending $S$ with a
binding from $l$ to $d$.  If $l \in \dom{S}$, then $\extSRaw{S}{l}{d}$
denotes an update to the existing binding for $l$, rather than an
extension.  Another way to denote a store is by explicitly writing out
all its bindings, using the notation
$\store{\storebindingRaw{l_1}{d_1}, \dots,
  \storebindingRaw{l_n}{d_n}}$.  The set of states that a store can take on forms a
lattice, just as $D$ does, with the empty store $\bot_S$ as its least
element and $\topS$ as its greatest element.  It is straightforward to
lift the $\userleq$ and $\sqcup$ operations defined on elements of $D$
to the level of stores:

\LVarsDefLeqStore

\LVarsDefLubStore

By Definition~\ref{def:lvars-lubstore}, if $\userlub{d_1}{d_2} =
\top$, then
$\lubstore{\store{\storebindingRaw{l}{d_1}}}{\store{\storebindingRaw{l}{d_2}}}
= \topS$.  Notice that a store containing a binding
$\storebindingRaw{l}{\top}$ can never arise during the execution of a
$\lambdaLVar$ program, because (as \either{I}{we} will show in
Section~\ref{s:lvars-lambdalvar}) an attempted write that would take
the state of some location $l$ to $\top$ would raise an error before the write can
occur.

\subsection{Communication primitives}\label{subsection:lvars-communication-primitives}

The @new@, @put@, and @get@ operations create, write to, and read
from LVars, respectively. The interface is similar to that presented
by mutable references:

\begin{itemize}
\item @new@ extends the store with a binding for a new LVar whose
  initial state is $\bot$, and returns the location $l$ of that LVar
  (\ie, a pointer to the LVar).
\item @put@ takes a pointer to an LVar and a new state and updates the
  LVar's state to the lub of the current state and the new state,
  potentially pushing the state of the LVar upward in the lattice.
  Any update that would take the state of an LVar to $\top$ results in
  an error.
\item @get@ performs a blocking ``threshold'' read that allows limited
  observations of the state of an LVar.  It takes a pointer to an LVar
  and a \emph{threshold set} $T$, which is a non-empty subset of $D$
  that is \emph{pairwise incompatible}, meaning that the lub of any
  two distinct elements in $T$ is $\top$.  If the LVar's state $d_1$
  in the lattice is \emph{at or above} some $d_2 \in T$, the @get@
  operation unblocks and returns $d_2$.  Note that $d_2$ is a unique
  element of $T$, for if there is another $d_2' \neq d_2$ in the
  threshold set such that $d_2' \userleq d_1$, it would follow that
  $d_2 \sqcup d_2' \userleq d_1$, and so $d_2 \sqcup d_2'$ cannot be
  $\top$, which contradicts the requirement that $T$ be pairwise
  incompatible.
\end{itemize}

The intuition behind @get@ is that it specifies a subset of the
lattice that is ``horizontal'': no two elements in the threshold set
can be above or below one another.  Intuitively, each element in the
threshold set is an ``alarm'' that detects the activation of itself or
any state above it.  One way of visualizing the threshold set for a
@get@ operation is as a subset of edges in the lattice that, if
crossed, set off the corresponding alarm.  Together these edges form a
``tripwire''.  Figure~\ref{f:lvars-example-lattices}(c) shows what the
``tripwire'' looks like for an example @get@ operation.  The
threshold set $\stateset{(\bot, 0), (\bot, 1), ...}$ (or a subset
thereof) would pass the incompatibility test, as would the threshold
set $\stateset{(0, \bot), (1, \bot), ...}$ (or a subset thereof), but
a combination of the two would not pass.

The requirement that the elements of a threshold set be pairwise
incompatible limits the expressivity of threshold sets.  In fact, it
is a stronger requirement than we need to ensure determinism.  Later
on, in Section~\ref{s:lvars-generalizing}, \either{I}{we} will explain how to
generalize the definition of threshold sets to allow more programs
to be expressed.  For now, \either{I}{we} will proceed with the simpler definition
above.

\subsection{Monotonic store growth and determinism}\label{subsection:lvars-monotonic-store-growth}

In IVar-based languages, a store can only change in one of two ways: a
new, empty location (pointing to $\bot$) is created, or a previously
$\bot$ binding is permanently updated to a meaningful value.  It is
therefore straightforward in such languages to define an ordering on
stores and establish determinism based on the fact that stores grow
monotonically with respect to the ordering. For instance,
\emph{Featherweight CnC}~\cite{CnC}, a single-assignment imperative
calculus that models the Intel Concurrent Collections (CnC) system,
defines ordering on stores as follows:\footnote{A minor difference
  between $\lambdaLVar$ and Featherweight CnC is that, in
  Featherweight CnC, no store location is explicitly bound to $\bot$.
  Instead, if $l \notin \dom{S}$, then $l$ is defined to point to
  $\bot$.}

\LVarsDefLeqStoreCnC

Our Definition~\ref{def:lvars-leqstore} is reminiscent of
Definition~\ref{def:lvars-leqstore-cnc}, but
Definition~\ref{def:lvars-leqstore-cnc} requires that $S(l)$ and
$S'(l)$ be \emph{equal}, instead of our weaker requirement that $S(l)$
be \emph{less than or equal to} $S'(l)$ according to the
given lattice $\userleq$.  In $\lambdaLVar$, stores may
grow by updating existing bindings via repeated @put@s, so
Definition~\ref{def:lvars-leqstore-cnc} would be too strong; for
instance, if $\bot \userlt d_1 \userleq d_2$ for distinct $d_1, d_2
\in D$, the relationship
$\leqstore{\store{\storebindingRaw{l}{d_1}}}{\store{\storebindingRaw{l}{d_2}}}$
holds under Definition~\ref{def:lvars-leqstore}, but would not hold
under Definition~\ref{def:lvars-leqstore-cnc}.  That is, in
$\lambdaLVar$ an LVar could take on the state $d_1$, and then later the state $d_2$,
which would not be possible in Featherweight CnC.

\either{I}{We} establish in Section~\ref{s:lvars-proof} that $\lambdaLVar$ remains
deterministic despite the relatively weak $\leqstore{}{}$ relation
given in Definition~\ref{def:lvars-leqstore}.  The key to maintaining
determinism is the blocking semantics of the @get@ operation and the
fact that it allows only \emph{limited} observations of the state of
an LVar.
