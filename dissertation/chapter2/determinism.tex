\section{Proof of determinism for $\lambdaLVar$}\label{s:lvars-proof}

The main technical result of this \either{chapter}{section} is a proof of determinism
for the $\lambdaLVar$ language.  The determinism theorem says that if
two executions starting from a given configuration $\conf$ terminate
in configurations $\conf'$ and $\conf''$, then $\conf'$ and $\conf''$
are the same configuration, up to a permutation on locations.  (\either{I}{We}
discuss permutations in more detail below, in
Section~\ref{subsection:lvars-permutations}.)

In order to prove determinism for $\lambdaLVar$, \either{I}{we} first prove several
supporting lemmas.  Lemma~\ref{lem:lvars-permutability}
(Permutability) deals with location names, and
Lemma~\ref{lem:lvars-locality} (Locality) establishes a useful
property for dealing with expressions that decompose into redex and
context in multiple ways.  After that point, the structure of the
proof is similar to that of the proof of determinism for Featherweight
CnC given by Budimli\'c \etal~\shortcite{CnC}.  \either{I}{We} reuse the naming
conventions of Budimli\'c \etal~for
Lemmas~\ref{lem:lvars-monotonicity} (Monotonicity),
\ref{lem:lvars-independence} (Independence), \ref{lem:lvars-clash}
(Clash), \ref{lem:lvars-error-preservation} (Error Preservation), and
\ref{lem:lvars-strong-local-confluence} (Strong Local
Confluence). However, the statements and proofs of those properties
differ considerably in the setting of $\lambdaLVar$, due to the
generality of LVars and other differences between the $\lambdaLVar$
language and Featherweight CnC.

On the other hand, Lemmas~\ref{lem:lvars-strong-one-sided-confluence}
(Strong One-Sided Confluence), \ref{lem:lvars-strong-confluence}
(Strong Confluence), and \ref{lem:lvars-confluence} (Confluence) are
nearly identical to the corresponding lemmas in the Featherweight CnC
determinism proof.  This is the case because, once
Lemmas~\ref{lem:lvars-monotonicity} through
\ref{lem:lvars-strong-local-confluence} are established, the remainder
of the determinism proof does not need to deal specifically with the
semantics of LVars, lattices, or the store, and instead deals only
with execution steps at a high level.

\ifdefined\JOURNAL
For brevity, we only give the statements of the properties we are
proving here; their proofs appear in~\cite{lvars-dissertation}.
\fi

\subsection{Permutations and permutability}\label{subsection:lvars-permutations}

The {\sc E-New} rule allocates a fresh location $l \in \Loc$ in the
store, with the only requirement on $l$ being that it is not (yet) in
the domain of the store.  Therefore, multiple runs of the same program
may differ in what locations they allocate, and therefore the
reduction semantics is nondeterministic with respect to which
locations are allocated.  Since this is not a kind of nondeterminism
that we care about, we work modulo an arbitrary \emph{permutation} on
locations.

Recall from Section~\ref{subsection:lvars-stores} that we have a
countable set of locations $\Loc$.  Then, a permutation is defined as
follows:
\LVarsDefPermutation
Condition (1) in Definition~\ref{def:lvars-permutation} ensures that
we only consider location renamings that we can ``undo'', and
condition (2) ensures that we only consider renamings of a finite
number of locations.  Equivalently, we can say that $\pi$ is a
bijection from $\Loc$ to $\Loc$ such that it is the identity on all
but finitely many elements.
\ifdefined\JOURNAL
We can lift Definition~\ref{def:lvars-permutation} to expressions,
stores, and configurations in the obvious way.
\fi

\ifdefined\DISSERTATION
Definitions~\ref{def:lvars-permutation-expression},
\ref{def:lvars-permutation-store},
and~\ref{def:lvars-permutation-configuration} lift
Definition~\ref{def:lvars-permutation} to expressions, stores, and
configurations, respectively.  There is nothing surprising about these
definitions: to apply a permutation $\pi$ to an expression, we just
apply $\pi$ to any locations that occur in the expression.  We can
also lift $\pi$ to evaluation contexts, structurally: $\pi([~]) =
[~]$, $\pi(\app{E}{e} = \app{\pi(E)}{\pi(e)}$, and so on.  To lift
$\pi$ to stores, we apply $\pi$ to all locations in the domain of the
store.  (We do not have to do any renaming in the codomain of the
store, since location names cannot occur in elements of the lattice
$D$ and hence cannot occur in the contents of other store locations.)
Since $\pi$ is a bijection, it follows that if some location $l$ is
not in the domain of some store $S$, then $\pi(l) \notin
\dom{(\pi(S)}$,\lk{Do I need to spell out why this is true?} a fact
that will be useful to us shortly.

\LVarsDefPermutationExpression

\LVarsDefPermutationStore

\LVarsDefPermutationConfiguration
\fi

With these definitions in place, \either{I}{we} can prove
Lemma~\ref{lem:lvars-permutability}, which says that the names of
locations in a configuration do not affect whether or not that
configuration can take a step: a configuration $\conf$ can step to
$\conf'$ exactly when $\pi(\conf)$ can step to $\pi(\conf')$.

\LVarsLemPermutability
\ifdefined\DISSERTATION
\begin{proof}
  See Section~\ref{section:lvars-permutability-proof}.  The forward
  direction of part~\ref{thm:permutable-reduction-transitions} is by
  cases on the rule in the reduction semantics by which $\conf$ steps
  to $\conf'$; the only interesting case is the {\sc E-New} case, in
  which we make use of the fact that if $l \notin \dom{S}$, then
  $\pi(l) \notin \dom{\pi(S)}$. The reverse direction of
  part~\ref{thm:permutable-reduction-transitions} relies on the fact
  that if $\pi$ is a permutation, then $\piinv$ is also a permutation.
  Part~\ref{thm:permutable-context-transitions} of the proof builds on
  part~\ref{thm:permutable-reduction-transitions}.
\end{proof}
\fi

\noindent Because the names of locations in a configuration do not affect
whether it can step, we can rename locations as needed, which will be
important later on when proving the \emph{confluence} lemmas of
Section~\ref{subsection:lvars-confluence}.\footnote{For another
  example of using permutations in the metatheory of a language to
  account for an allocator's nondeterministic choice of locations in
  an otherwise deterministic setting, see
  Krishnaswami~\shortcite{simple-frp}.}

\subsection{Internal determinism}

\either{My}{Our} goal is to show that $\lambdaLVar$ is deterministic according to
the definition of \emph{observable determinism} that \either{I}{we} gave in
\either{Chapter}{Section}~\ref{ch:intro}---that is, that a $\lambdaLVar$ program always
evaluates to the same value.  In the context of $\lambdaLVar$, a
``program'' can be understood as a configuration, and a ``value'' can
be understood as a configuration that cannot step, either because the
expression in that configuration is actually a $\lambdaLVar$ value, or because it is
a ``stuck'' configuration that cannot step because no rule of the
operational semantics applies.  In $\lambdaLVar$, the latter situation
could occur if, for instance, a configuration contains a blocking
@get@ expression and there are no other expressions left to evaluate
that might cause it to unblock.

This definition of observable determinism does \emph{not} require that
a configuration takes the same sequence of steps on the way to
reaching its value at the end of every run.
Borrowing terminology from
Blelloch~\etal~\shortcite{blelloch-internally-deterministic}, \either{I}{we} will use
the term \emph{internally deterministic} to describe a program that
does, in fact, take the same sequence of steps on every
run.\footnote{\either{I am}{We are} using ``internally deterministic'' in a more
  specific way than Blelloch~\etal: they define an internally
  deterministic program to be one for which the \emph{trace} of the
  program is the same on every run, where a trace is a directed
  acyclic graph of the operations executed by the program and the
  control dependencies among them.  This definition, in turn, depends
  on the definition of ``operation'', which might be defined in a
  fine-grained way or a coarse-grained, abstract way, depending on
  which aspects of program execution one wants the notion of internal
  determinism to capture.  The important point is that internal
  determinism is a stronger property than observable determinism.}
Although $\lambdaLVar$ is not internally deterministic, all of its
internal nondeterminism is due to the {\sc E-Eval-Ctxt} rule!  This is
the case because the {\sc E-Eval-Ctxt} rule is the only rule in the
operational semantics by which a particular configuration can step in
multiple ways.  The multiple ways in which a configuration can step
via {\sc E-Eval-Ctxt} correspond to the ways in which the expression
in that configuration can be decomposed into a redex and an evaluation
context.  In fact, it is exactly this property that makes it possible
for multiple subexpressions of a $\lambdaLVar$ expression (a @let par@
expression, for instance) to be evaluated in parallel.

But, leaving aside evaluation contexts for the moment---we will return to them in the following section---let us focus on the rules of the reduction semantics in
Figure~\ref{f:lvars-lambdaLVar-reduction-semantics}.  Here we can see that if a
given configuration can step by the reduction semantics, then there is
only one rule by which it can step, and only one configuration to
which it can step.  The only exception is the {\sc E-New} rule, which
nondeterministically allocates locations and returns pointers to
them---but we can account for this by saying that the reduction
semantics is internally deterministic up to a permutation on
locations.  Lemma~\ref{lem:lvars-internal-determinism} formalizes this
claim, which we will later use in the proof of Strong Local Confluence
(Lemma~\ref{lem:lvars-strong-local-confluence}).

\LVarsLemInternalDeterminism
\ifdefined\DISSERTATION
\begin{proof}
  Straightforward by cases on the rule of the reduction semantics by
  which $\conf$ steps to $\conf'$; the only interesting case is for
  the {\sc E-New} rule.  See
  Section~\ref{section:lvars-internal-determinism-proof}.
\end{proof}
\fi

\subsection{Locality}

In order to prove determinism for $\lambdaLVar$, we will have to
consider situations in which we have an expression that decomposes
into redex and context in multiple ways.  Suppose that we have an
expression $e$ such that $e = \evalctxt{E_1}{e_1} =
\evalctxt{E_2}{e_2}$.  The configuration $\config{S}{e}$ can then step
in two different ways by the {\sc E-Eval-Ctxt} rule:
$\config{S}{\evalctxt{E_1}{e_1}} \ctxstepsto
\config{S_1}{\evalctxt{E_1}{e'_1}}$, and
$\config{S}{\evalctxt{E_2}{e_2}} \ctxstepsto
\config{S_2}{\evalctxt{E_2}{e'_2}}$.

The interesting case is the one where $E_1$ and $E_2$ are different.
The key observation we can make here is that the $\ctxstepsto$
relation acts ``locally''.  That is, when $e_1$ steps to $e'_1$ within
its context, the expression $e_2$ will be left alone, because it
belongs to the context.  Likewise, when $e_2$ steps to $e'_2$ within
its context, the expression $e_1$ will be left alone.
Lemma~\ref{lem:lvars-locality} formalizes this claim.

\LVarsLemLocality
\ifdefined\DISSERTATION
\begin{proof}
  \TODO{Add short description here once the proof is done.} See
  Section~\ref{section:lvars-locality-proof}.
\end{proof}
\fi

\subsection{Monotonicity}

The Monotonicity lemma says that, as evaluation proceeds according to
the $\parstepsto$ relation, the store can only grow with respect to
the $\leqstore{}{}$ ordering.

\LVarsLemMonotonicity
\ifdefined\DISSERTATION
\begin{proof}
  Straightforward by cases on the rule of the reduction semantics by
  which $\config{S}{e}$ steps to $\config{S'}{e'}$. The interesting
  cases are for the {\sc E-New} and {\sc E-Put} rules.  See
  Section~\ref{section:lvars-monotonicity-proof}.
\end{proof}
\fi

\subsection{Independence}\label{subsection:lvars-independence}

\begin{figure}
    Frame rule:
    \begin{mathpar}
      \inferrule*
          {\lbrace p \rbrace ~ C ~ \lbrace q \rbrace}
          {\lbrace p * r \rbrace ~ C ~ \lbrace q * r \rbrace}
    \end{mathpar}
    \\
    Lemma~\ref{lem:lvars-independence} (Independence), simplified:
    \begin{mathpar}
      \inferrule*
          {\config{S}{e} \parstepsto \config{S'}{e'}}
          {\config{\lubstore{S}{S''}}{e} \parstepsto \config{\lubstore{S'}{S''}}{e'}}
    \end{mathpar}
  \caption{Comparison of O'Hearn~\etal's frame
    rule~\protect\shortcite{OHearnLocalReasoning} and a simplified version
    of the Independence lemma.  The separating conjunction connective
    $*$ in the frame rule requires that its arguments be disjoint; the
    Independence lemma uses the $\lubstore{}{}$ operation in place of
    $*$.}
  \label{f:lvars-frame-rule}
\end{figure}

Figure~\ref{f:lvars-frame-rule} shows a \emph{frame rule}, due to
O'Hearn \etal~\shortcite{OHearnLocalReasoning}, which captures the idea of
\emph{local reasoning} about programs that alter state.  In it, $C$ is
a program, and $\lbrace p \rbrace ~ C ~ \lbrace q \rbrace$ is a
\emph{Hoare triple} (in the style of Hoare
logic~\shortcite{HoareAxiomatic}) specifying the behavior of $C$: it says
that if the assertion $p$ is true before $C$ runs, then the assertion
$q$ will be true afterwards.  For example, $p$ and $q$ might
respectively describe the state of the heap before and after a heap
location is updated by $C$.

Given a program $C$ with precondition $p$ and postcondition $q$, the
frame rule tells us that running $C$ starting from a state satisfying
the precondition $p * r$ will result in a state satisfying the
postcondition $q * r$.  These two assertions use the \emph{separating
  conjunction} connective $*$, which combines two assertions that can
be satisfied in a \emph{non-overlapping} manner.  For instance, the
assertion $p * r$ is satisfied by a heap if the heap can be split into
two non-overlapping parts satisfying $p$ and $r$, respectively.

Therefore, if $C$ can run safely starting from a state satisfying $p$
and end in a state satisfying $q$, then it does not do any harm to
also have the disjoint property $r$ be true when $C$ runs: the truth
of $r$ will not interfere with the safe execution of $C$.
Furthermore, if $r$ is true to begin with, running $C$ will not
interfere with the truth of $r$.  The frame rule gets its name from
the fact that $r$ is a ``frame'' around $C$: everything that is not
explicitly changed by $C$ is part of the frame and is
inviolate.\footnote{The ``frame'' terminology was originally
  introduced in 1969 by McCarthy and Hayes~\shortcite{McCarthyHayesFrame},
  who observed that specifying only what is changed by an action does
  not generally allow an intelligent agent to conclude that nothing
  else is changed; they called this dilemma the \emph{frame problem}.}
O'Hearn \etal~refer to the resources (such as heap locations) actually
used by $C$ as the ``footprint'' of $C$; $r$ is an assertion about
resources outside of that footprint.

The Independence lemma establishes a similar ``frame property'' for
$\lambdaLVar$ that captures the idea that independent effects commute
with each other.  Consider an expression $e$ that runs starting in
store $S$ and steps to $e'$, updating the store to $S'$.  The
Independence lemma provides a double-edged guarantee about what will
happen if we evaluate $e$ starting from a larger store
$\lubstore{S}{S''}$: we know both that $e$ will update the store to
$\lubstore{S'}{S''}$, and that $e$ will step to $e'$ as it did before.
Here, $\lubstore{S}{S''}$ is the lub of the original $S$ and some
other store $S''$ that is ``framed on'' to $S$; intuitively, $S''$ is
the store resulting from some other independently-running
computation.\footnote{See
  Section~\ref{s:related-frame-properties-and-separation-logics} for a
  more detailed discussion of frame properties and where they manifest
  in the LVars model.}

Lemma~\ref{lem:lvars-independence} requires as a precondition that the
store $S''$ must be \emph{non-conflicting} with the original
transition from $\config{S}{e}$ to $\config{S'}{e'}$, meaning that
locations in $S''$ cannot share names with locations newly allocated
during the transition; this rules out location name conflicts caused
by allocation.

\LVarsDefNonConflicting

\LVarsLemIndependence
\ifdefined\DISSERTATION
\begin{proof}
  By cases on the rule of the reduction semantics by which
  $\config{S}{e}$ steps to $\config{S'}{e'}$. The interesting cases
  are for the {\sc E-New} and {\sc E-Put} rules.  Since
  $\config{S'}{e'} \neq \error$, we do not need to consider the {\sc
    E-Put-Err} rule.  See
  Section~\ref{section:lvars-independence-proof}.
\end{proof}
\fi

\subsection{Clash}

The Clash lemma, Lemma~\ref{lem:lvars-clash}, is similar to the
Independence lemma, but handles the case where $\lubstore{S'}{S''} =
\topS$.  It establishes that, in that case,
$\config{\lubstore{S}{S''}}{e}$ steps to $\error$.

\LVarsLemClash
\ifdefined\DISSERTATION
\begin{proof}
  By cases on the rule of the reduction semantics by which
  $\config{S}{e}$ steps to $\config{S'}{e'}$. As with
  Lemma~\ref{lem:lvars-independence}, the interesting cases are for
  the {\sc E-New} and {\sc E-Put} rules, and since $\config{S'}{e'}
  \neq \error$, we do not need to consider the {\sc E-Put-Err} rule.
  See Section~\ref{section:lvars-clash-proof}.
\end{proof}
\fi

\subsection{Error preservation}

Lemma~\ref{lem:lvars-error-preservation}, Error Preservation, says
that if a configuration $\config{S}{e}$ steps to $\error$, then
evaluating $e$ in the context of some larger store will also result in
$\error$.

\LVarsLemErrorPreservation
\ifdefined\DISSERTATION
\begin{proof}
  Suppose $\config{S}{e} \parstepsto \error$ and
  $\leqstore{S}{S'}$. We are required to show that $\config{S'}{e}
  \parstepsto \error$.

  By inspection of the operational semantics, the only rule by which
  $\config{S}{e}$ can step to $\error$ is {\sc E-Put-Err}.  Hence $e =
  \putexp{l}{d_2}$.  From the premises of {\sc E-Put-Err}, we have
  that $S(l) = d_1$.  Since $\leqstore{S}{S'}$, it must be the case
  that $S'(l) = d'_1$, where $d_1 \userleq d'_1$.  Since
  $\userlub{d_1}{d_2} = \top$, we have that $\userlub{d'_1}{d_2} =
  \top$.  Hence, by {\sc E-Put-Err}, $\config{S'}{\putexp{l}{d_2}}
  \parstepsto \error$, as we were required to show.
\end{proof}
\fi

\subsection{Confluence}\label{subsection:lvars-confluence}

Lemma~\ref{lem:lvars-strong-local-confluence}, the Strong Local
Confluence lemma, says that if a configuration $\conf$ can step to
configurations $\conf_a$ and $\conf_b$, then there exists a
configuration $\conf_c$ that $\conf_a$ and $\conf_b$ can each reach in
at most one step, modulo a permutation on the locations in $\conf_b$.
Lemmas~\ref{lem:lvars-strong-one-sided-confluence}
and~\ref{lem:lvars-strong-confluence} then generalize that result to
arbitrary numbers of steps.

The structure of this part of the proof differs from the Budimli\'c
\etal~determinism proof for Featherweight CnC in two ways.  First,
Budimli\'c \etal~prove a \emph{diamond} property, in which $\conf_a$
and $\conf_b$ each step to $\conf_c$ in \emph{exactly} one step.  They
then get a property like Lemma~\ref{lem:lvars-strong-local-confluence}
as an immediate consequence of the diamond property, by choosing $i =
j = 1$.  But a true diamond property with exactly one step ``on each
side of the diamond'' is stronger than we need here, and, in fact,
does not hold for $\lambdaLVar$; so, instead, \either{I}{we} prove the weaker ``at
most one step'' property directly.

Second, Budimli\'c \etal~do not have to deal with permutations in
their proof, because the Featherweight CnC language does no
allocation; there is no counterpart to $\lambdaLVar$'s $\NEW$
expression in Featherweight CnC.  Instead, Featherweight CnC models
the store as a pre-existing array of locations, where every location
has a default initial value of $\bot$.  Because there is no way (and
no need) to allocate new locations in Featherweight CnC, it is never
the case that two subexpressions independently happen to allocate
locations with the same name---which is exactly the situation that
requires us to be able to rename locations in $\lambdaLVar$.  In fact,
that situation is what makes the entire notion of permutations
described in Section~\ref{subsection:lvars-permutations} a necessary
part of the metatheory of $\lambdaLVar$.

Taking the approach of Featherweight CnC, and therefore avoiding
allocation entirely, would simplify both the $\lambdaLVar$ language
and its determinism proof.  On the other hand, when programming with
the LVish Haskell library of \either{Chapter}{Section}~\ref{ch:lvish}, one does have to
explicitly create and allocate new LVars by calling the equivalent of
$\NEW$, and so by modeling the $\NEW$ operation in $\lambdaLVar$, we
keep the semantics a bit more faithful to the implementation.

\LVarsLemStrongLocalConfluence
\ifdefined\DISSERTATION
\begin{proof}
  Since the original configuration $\conf$ can step in two different
  ways, its expression decomposes into redex and context in two
  different ways: $\conf = \config{S}{\evalctxt{E_a}{e_{a_1}}} =
  \config{S}{\evalctxt{E_b}{e_{b_1}}}$, where $\evalctxt{E_a}{e_{a_1}}
  = \evalctxt{E_b}{e_{b_1}}$, but $E_a$ and $E_b$ may differ and
  $e_{a_1}$ and $e_{b_1}$ may differ.  In the special case where $E_a
  = E_b$, the result follows by Internal Determinism
  (Lemma~\ref{lem:lvars-internal-determinism}).

  If $E_a \neq E_b$, we can apply the Locality lemma
  (Lemma~\ref{lem:lvars-locality}); at a high level, it shows that
  $e_{a_1}$ and $e_{b_1}$ can be evaluated independently within their
  contexts.  The proof is then by a double case analysis on the rules
  of the reduction semantics by which $\config{S}{e_{a_1}}$ steps and
  by which $\config{S}{e_{b_1}}$ steps.  In order to combine the
  results of the two independent steps, the proof makes use of the
  Independence lemma (Lemma~\ref{lem:lvars-independence}).  The most
  interesting case is that in which both steps are by the {\sc E-New}
  rule and they allocate locations with the same name.  In that case,
  we can use the Permutability lemma
  (Lemma~\ref{lem:lvars-permutability}) to rename locations so as not
  to conflict.  See
  Section~\ref{section:lvars-strong-local-confluence-proof}.
\end{proof}
\fi

\LVarsLemStrongOneSidedConfluence
\ifdefined\DISSERTATION
\begin{proof}
  By induction on $m$; see
  Section~\ref{section:lvars-strong-one-sided-confluence-proof}.
\end{proof}
\fi

\LVarsLemStrongConfluence
\ifdefined\DISSERTATION
\begin{proof}
  By induction on $n$; see
  Section~\ref{section:lvars-strong-confluence-proof}.
\end{proof}
\fi

\ifdefined\JOURNAL
\noindent Directly following from Strong Confluence is Confluence:
\fi

\LVarsLemConfluence
\ifdefined\DISSERTATION
\begin{proof}
  Strong Confluence (Lemma~\ref{lem:lvars-strong-confluence}) implies
  Confluence.
\end{proof}
\fi

\subsection{Determinism}

Finally, the determinism theorem, Theorem~\ref{thm:lvars-determinism},
is a direct result of Lemma~\ref{lem:lvars-confluence}:

\LVarsThmDeterminism
\ifdefined\DISSERTATION
\begin{proof}
  We have from Confluence (Lemma~\ref{lem:lvars-confluence}) that
  there exists $\conf_c$ and $\pi$ such that $\conf' \ctxstepsto^*
  \conf_c$ and $\pi(\conf'') \ctxstepsto^* \conf_c$.  Since $\conf'$
  cannot step, we must have $\conf' = \conf_c$.

  By Permutability (Lemma~\ref{lem:lvars-permutability}), $\conf''$
  can step iff $\pi(\conf'')$ can step, so since $\conf''$ cannot
  step, $\pi(\conf'')$ cannot step either.

  Hence we must have $\pi(\conf'') = \conf_c$.  Since $\conf' =
  \conf_c$ and $\pi(\conf'') = \conf_c$, $\conf' = \pi(\conf'')$.
\end{proof}
\fi

\subsection{Discussion: termination}

\either{I}{We} have followed Budimli\'c \etal~\shortcite{CnC} in treating
\emph{determinism} separately from the issue of \emph{termination}.
Yet one might legitimately be concerned that in $\lambdaLVar$, a
configuration could have both an infinite reduction path and one that
terminates with a value.  Theorem~\ref{thm:lvars-determinism} says
that if two runs of a given $\lambdaLVar$ program reach configurations
where no more reductions are possible, then they have reached the same
configuration.  Hence Theorem~\ref{thm:lvars-determinism} handles the
case of \emph{deadlocks} already: a $\lambdaLVar$ program can deadlock
(\eg, with a blocked $\GET$), but it will do so deterministically.

However, Theorem~\ref{thm:lvars-determinism} has nothing to say about
\emph{livelocks}, in which a program reduces infinitely.  It would be
desirable to have a \emph{consistent termination} property which would
guarantee that if one run of a given $\lambdaLVar$ program terminates
with a non-$\error$ result, then every run will.  \either{I}{We} conjecture (but do
not prove) that such a consistent termination property holds for
$\lambdaLVar$.  Such a property could be paired with
Theorem~\ref{thm:lvars-determinism} to guarantee that if one run of a
given $\lambdaLVar$ program terminates in a non-$\error$ configuration
$\sigma$, then every run of that program terminates in $\sigma$.  (The
``non-$\error$ configuration'' condition is necessary because it is
possible to construct a $\lambdaLVar$ program that can terminate in
$\error$ on some runs and diverge on others.  By contrast, the
existing determinism theorem does not have to treat $\error$
specially.)
