\chapter{Related work}\label{ch:related} % 6

Work on deterministic parallel programming models is long-standing.
As we have seen, what deterministic parallel programming models have
in common is that they all must do something to restrict access to
mutable state shared among concurrent computations so that schedule
nondeterminism cannot be observed.  Depending on the model,
restricting access to shared mutable state might involve disallowing
sharing entirely~\cite{dph}, only allowing single assignments to
shared references~\cite{Tesler-1968, IStructures, CnC}, allowing
sharing only by a limited form of message passing~\cite{Kahn-1974},
ensuring that concurrent accesses to shared state are
disjoint~\cite{dpj-oopsla}, resolving conflicting updates after the
fact~\cite{concurrent-revisions-haskell11}, or some combination of
these approaches.  These constraints can be imposed at the language or
API level, within a type system or at runtime.

In particular, the LVars model was inspired by two traditional
deterministic parallel programming models based on
monotonically-growing shared data structures: first, Kahn process
networks~\cite{Kahn-1974}, in which a network of processes communicate
with each other through blocking FIFO channels with ever-growing
{\emph channel histories}; and, second, IVars~\cite{IStructures},
single-assignment locations with blocking read semantics.

LVars are general enough to subsume both IVars and KPNs: a lattice of
channel histories with a prefix ordering allows LVars to represent
FIFO channels that implement a Kahn process network, whereas
instantiating $\lambdaLVar$ with a lattice with one ``empty'' state
and multiple ``full'' states (where $\forall{i}.\; \mathit{empty} <
\mathit{full_i}$) results in a parallel single-assignment language
with a store of IVars, as we saw in Chapter~\ref{ch:lvars}.  Hence
LVars provide a framework for generalizing and unifying these two
existing approaches to deterministic parallelism.  In this chapter, I
describe some more recent contributions to the literature, and how the
LVars model relates to them.

\section{Deterministic Parallel Java (DPJ)}

DPJ \cite{dpj-oopsla, dpj-hotpar09} is a deterministic language
consisting of a system of annotations for Java code.  A sophisticated
region-based type system ensures that a mutable region of the heap is,
essentially, passed linearly to an exclusive writer, thereby ensuring
that the state accessed by concurrent threads is disjoint.  DPJ does,
however, provide a way to unsafely assert that operations commute with
one another (using the @commuteswith@ form) to enable concurrent
mutation.

The LVars model differs from DPJ in that it allows overlapping shared
state between threads as the default.  Moreover, since LVar effects
are already commutative, we avoid the need for @commuteswith@
annotations.  Finally, it is worth noting that while in DPJ,
commutativity annotations have to appear in application-level code, in
LVish only the data-structure author needs to write trusted code. The
application programmer can run untrusted code that still enjoys a
(quasi-)determinism guarantee, because only (quasi-)deterministic
programs can be expressed as LVish @Par@ computations.
More recently, Bocchino \etal~\cite{dpj-popl} proposed a type and
effect system that allows for the incorporation of nondeterministic
sections of code in DPJ.  The goal here is different from ours: while
they aim to support \emph{intentionally} nondeterministic computations
such as those arising from optimization problems like branch-and-bound
search, the quasi-determinism in LVish arises as a result of schedule
nondeterminism.

\section{FlowPools}

Prokopec \etal~\cite{flowpools} propose a data structure with an API
closely related to LVars extended with freezing and handlers: a
FlowPool is a bag (that is, a multiset) that allows concurrent
insertions but forbids removals, a @seal@ operation that forbids
further updates, and combinators like @foreach@ that invoke callbacks
as data arrives in the pool.  To retain determinism, the @seal@
operation requires explicitly passing the expected bag \emph{size} as
an argument, and the program will raise an exception if the bag goes
over the expected size.

While this interface has a flavor similar to that of LVars, it lacks
the ability to detect quiescence, which is crucial for expressing
algorithms like graph traversal, and the @seal@ operation is awkward
to use when the structure of data is not known in advance.  By
contrast, the @freeze@ operation on LVars does not require such
advance knowledge, but moves the model into the realm of
quasi-determinism.  Another important difference is the fact that
LVars are \emph{data structure-generic}: both our formalism and our
library support an unlimited collection of data structures, whereas
FlowPools are specialized to bags.

\section{Concurrent Revisions}

Burckhardt \etal~\cite{eventually-consistent-transactions} propose a
formalism for eventual consistency based on graphs called
\emph{revision diagrams}, and Leijen, Burckhardt, and Fahndrich apply
the revision diagrams approach to guaranteed-deterministic concurrent
functional programming~\cite{concurrent-revisions-haskell11}.  Their
\emph{Concurrent Revisions} (CR) programming model uses isolation
types to distinguish regions of the heap shared by multiple mutators.
Rather than enforcing exclusive access in the style of DPJ, CR clones
a copy of the state for each mutator, using a deterministic ``merge
function'' for resolving conflicts in local copies at join points.

In CR, variables can be annotated as being shared between a ``joiner''
thread and a ``joinee'' thread.  Unlike the least-upper-bound writes
of LVars, CR merge functions are \emph{not} necessarily commutative;
indeed, the default CR merge function is ``joiner wins''.  Determinism
is enforced by the programming model allowing the programmer to
specify which of two writing threads should prevail, regardless of the
order in which those writes arrive, and the states that a shared
variable can take on need not form a lattice.  Still, semilattices
turn up in the metatheory of CR: in particular, Burckhardt and
Leijen~\cite{semantics-concurrent-revisions} show that revision
diagrams are semilattices, and that therefore, for any two vertices in
a CR revision diagram, there exists a \emph{greatest common ancestor}
state that can be used to determine what changes each side has
made---an interesting duality with the LVars model (in which any two
LVar states have a least upper bound).

Although versioned variables in CR could model lattice-based data
structures---if they used least upper bound as their merge function
for conflicts---the programming model nevertheless differs from the
LVars model in that effects only become visible at the end of parallel
regions, as opposed to the asynchronous communication within parallel
regions that the LVars model allows.  This semantics precludes the use
of traditional lock-free data structures for representing versioned
variables.

\section{Conflict-free replicated data types}

In Chapter~\ref{ch:distributed}, I presented a way to equip
lattice-based distributed data structures with LVar-style threshold
reads, resulting in a way to make deterministic \emph{threshold
  queries} of them.  My is based on Shapiro \etal's work on
conflict-free replicated data types (CRDTs) \cite{crdts,crdts-tr} and
in particular their work on the lattice-based formulation of CRDTs,
called \emph{convergent replicated data types} or CvRDTs, which I
discuss in detail in Section~\ref{s:distributed-cvrdts}.

As we saw in Chapter~\ref{ch:distributed}, database services such as
Amazon's SimpleDB~\cite{simpledb-vogels-article} allow for both
eventually consistent and strongly consistent reads, chosen at a
per-query granularity.  Terry~\etal's Pileus key-value
store~\cite{pileus} takes the idea of mixing consistency levels
further: instead of requiring the application developer to choose the
consistency level of a particular query at development time, the
system allows the developer to specify a service-level agreement that
can dynamically adapt to changing network conditions, for instance.
Hence choosing consistency at a per-query level and mixing consistency
levels within a single application is not a new idea.  Rather, the new
contribution that I make by adding threshold queries to CvRDTs is to
establish lattice-based data structures as a unifying formal
foundation for both eventually consistent and strongly consistent
queries.

\section{Bloom and Bloom$^L$}

Other authors have also used lattices as a framework for establishing
formal guarantees about eventually consistent systems and distributed
programs.  The Bloom language for distributed database programming
guarantees eventual consistency for distributed data collections that
are updated monotonically.  The initial formulation of
Bloom~\cite{bloom-cidr} had a notion of monotonicity based on set
inclusion, which is analogous to the store ordering relation in the
(IVar-based) Featherweight CnC system that I described in
Section~\ref{subsection:lvars-monotonic-store-growth}.  Later, Conway
\etal~\cite{blooml} generalized Bloom to a more flexible
lattice-parameterized system, Bloom$^L$, in a manner analogous to the
generalization from IVars to LVars.  Bloom$^L$ combines ideas from the
aforementioned work on CRDTs~\cite{crdts, crdts-tr} with
\emph{monotonic logic}, resulting in a lattice-parameterized,
confluent language that is a close (but independently invented)
relative to the LVars model.  Bloom($^L$) is implemented as a
domain-specific language embedded in Ruby, and a monotonicity analysis
pass rules out programs that would perform non-monotonic operations on
distributed data collections (such as the removal of elements from a
set).  By contrast, in the LVars model (and in the LVish library),
monotonicity is enforced by the API presented by LVars, and since the
LVish library is implemented in Haskell, we can rely on Haskell's type
system for fine-grained effect tracking and monadic encapsulation of
LVar effects.

\section{Frame properties and separation logics}\label{s:related-frame-properties-and-separation-logics}

In Section~\ref{subsection:lvars-independence}, we saw that the
Independence lemma, Lemma~\ref{lem:lvars-independence}, expresses a
\emph{frame property} reminiscent of the following \emph{frame rule}
from separation logic and concurrent separation
logic~\cite{OHearnLocalReasoning, ReynoldsSeparationLogic,
  OHearnResourcesConcurrency}:
\begin{mathpar}
  \inferrule*
      {\lbrace p \rbrace ~ C ~ \lbrace q \rbrace}
      {\lbrace p * r \rbrace ~ C ~ \lbrace q * r \rbrace}
\end{mathpar}
Recall that $C$ is a program and $p$ and $q$ are respectively a
precondition and postcondition on $C$.  Putting them together,
$\lbrace p \rbrace ~ C ~ \lbrace q \rbrace$ is a specification of the
behavior of $C$.

The conclusion of the rule is written using the \emph{separating
  conjunction} connective $*$.  The assertion $p * r$ says that $p$
and $r$ are true and \emph{disjoint}; for instance, they might
describe disjoint pieces of the heap.  The frame rule says that if $C$
can run safely starting from a state satisfying $p$ and end in a state
satisfying $q$, then it does not do any harm to have the disjoint
property $r$ be true: $r$ will not interfere with the safe execution
of $C$.  Furthermore, if $r$ is true to begin with, running $C$ will
not interfere with the truth of $r$.

The frame rule gets its name from the fact that $r$ is a ``frame''
around $C$: everything that is not explicitly changed by $C$ is part
of the frame and is inviolate.\footnote{The ``frame'' terminology was
  originally introduced in 1969 by McCarthy and
  Hayes~\cite{McCarthyHayesFrame}, who observed that specifying only
  what is changed by an action does not generally allow an intelligent
  agent to conclude that nothing else is changed; they called this
  dilemma the \emph{frame problem}.}  O'Hearn \etal~refer to the parts
of the heap actually used by $C$ as the "footprint" of $C$, and $r$ is
outside of that footprint.  However, sometimes we do in fact want to
allow some amount of ``physical'' overlap between $p$ and $r$ or
between $q$ and $r$, while retaining ``logical'' separation.  In fact,
the Independence lemma, since it replaces the separating conjunction
with the least upper bound operation, allows a limited amount of
overlap between the original store and the ``frame'' store $S''$.
Recent work by Jensen and Birkedal on \emph{fictional separation
  logic}~\cite{JensenBirkedalFictional} explores this idea in detail,
generalizing separation logic to allow more sophisticated kinds of
sharing.

Even more recently, Dinsdale-Young \etal~\cite{views} introduced the
``Views'' framework, which brings the notion of fictional separation
to a concurrent setting.  The Views framework is a metatheory of
concurrent reasoning principles that generalizes a variety of
concurrent program logics and type systems, including concurrent
separation logic.  It provides a generalized frame rule, which is
parameterized by a function $f$ that is applied to the pre- and
post-conditions in the conclusion of the rule:
\begin{mathpar}
  \inferrule*
      {\lbrace p \rbrace ~ C ~ \lbrace q \rbrace}
      {\lbrace f(p) \rbrace ~ C ~ \lbrace f(q) \rbrace}
\end{mathpar}
In this formulation of the rule, the ``frame'' is an abstract piece of
knowledge that is not violated by the execution of $C$.  The
Generalized Independence lemma
(Lemma~\ref{lem:generalized-independence}) that I describe in
Section~\ref{subsection:quasi-generalized-independence}, which extends
the Independence lemma to handle arbitrary update operations, is
reminiscent of this generalized frame rule.
