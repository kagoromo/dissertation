\ifdefined\DISSERTATION
The LVars programming model presented in Chapter~\ref{ch:lvars} is
based on the idea of \emph{monotonic data structures}, in which
information can only be added, never removed, and the timing with
which information is added (and hence the \emph{order} in which it is
added) is not observable.  A paradigmatic example is a set that
supports insertion but not removal, but there are many others.  In the
LVars model, all shared data structures (called LVars) are monotonic,
and the states that an LVar can take on form a \emph{lattice}.  Writes
to an LVar must correspond to a lub operation in the lattice, which
means that they monotonically increase the information in the LVar,
and that they commute with one another.  But commuting writes are not
enough to guarantee determinism: if a read can observe whether or not
a concurrent write has happened, then it can observe differences in
scheduling.  So, in the LVars model, the answer to the question ``has
a write occurred?''  (\ie, is the LVar above a certain lattice value?)
is always
\emph{yes}; the reading thread will block until the LVar's contents
reach a desired threshold.  In a monotonic data structure, the absence
of information is transient---another thread could add that
information at any time---but the presence of information is forever.
\fi

The LVars model \either{}{of Section~\ref{ch:lvars}} guarantees determinism and supports an unlimited
variety of shared data structures: anything viewable as a lattice.
However, it is not as general-purpose as one might hope.  Consider
again the graph traversal problem that we saw in 
\ifdefined\DISSERTATION
Chapter~\ref{ch:lvars}:
\begin{blockquote}
  In a directed graph, find the connected component containing a
  vertex $v$, and compute a (possibly expensive) function $f$ over all
  vertices in that component, making the set of results available
  asynchronously to other computations.
\end{blockquote}
In Section~\ref{s:lvars-motivation}, we considered an attempt at a
solution using purely functional parallelism (shown
in Figure~\ref{f:bfs-pure}).  Unfortunately, our purely functional
attempt did not quite satisfy the above specification: although
connected component discovery proceeded in parallel, members of the
output set did not become available to other computations until the
entire connected component had been traversed, limiting parallelism.

\fi
\ifdefined\JOURNAL
Section~\ref{s:lvars-motivation}.
\fi
What would happen if we tried to solve this problem using LVars?  A
typical implementation of the graph-traversal part of the
problem---including the purely functional implementation of
Section~\ref{s:lvars-motivation}---involves a monotonically growing
set of ``seen nodes''; neighbors of seen nodes are fed back into the
set until it reaches a fixed point.  Such fixpoint computations are
ubiquitous, and would seem to be a perfect match for the LVars model
due to their use of monotonicity.  But they are not expressible using
the threshold read and least-upper-bound write operations of the basic
LVars model.

The problem is that these computations rely on \emph{negative}
information about a monotonic data structure, \ie, on the
\emph{absence} of certain writes to the data structure.  In a graph
traversal, for example, neighboring nodes should only be explored if
the current node is \emph{not yet} in the set; a fixpoint is reached
only if no new neighbors are found; and, of course, at the end of the
computation it must be possible to learn exactly which nodes were
reachable (which entails learning that certain nodes were not).  But
in the LVars model, asking whether a node is in a set means waiting
until the node \emph{is} in the set, and it is not clear how to lift
this restriction while retaining determinism.

In this \either{chapter, I}{section, we} describe two extensions to the basic LVars model of
\either{Chapter}{Section}~\ref{ch:lvars} that make it possible for monotonic data
structures to ``say no'':

\begin{itemize}
\item First, \either{I}{we} extend the model with a primitive operation @freeze@
  for \emph{freezing} an LVar, which comes with the following
  tradeoff: once an LVar is frozen, any further writes that would
  change its value instead throw an exception; on the other hand, it
  becomes possible to discover the exact value of the LVar, learning
  both positive and negative information about it, without blocking.
\item
  Second, \either{I}{we} add the ability to attach \emph{event handlers} to an
  LVar.  When an event handler has been registered with an LVar, it
  invokes a \emph{callback function} to run asynchronously, whenever
  events arrive (in the form of monotonic updates to the LVar).
  Ordinary LVar reads encourage a synchronous, \emph{pull} model of
  programming in which threads ask specific questions of an LVar,
  potentially blocking until the answer is ``yes''.  Handlers, by
  contrast, support an asynchronous, \emph{push} model of programming.
  Crucially, it is possible to check for \emph{quiescence} of a
  handler, discovering that no callbacks are currently enabled---a
  transient, negative property.  Since quiescence means that there are
  no further changes to respond to, it can be used to tell that a
  fixpoint has been reached.
\end{itemize}

Unfortunately, freezing does not commute with writes that change an
LVar.\footnote{The same is true for quiescence detection; see
Section~\ref{subsection:quasi-quiescence}.}  If a freeze is
interleaved before such a write, the write will raise an exception; if
it is interleaved afterwards, the program will proceed normally.  It
would appear that the price of negative information is the loss of
determinism!

Fortunately, the loss is not total.  Although LVar programs with
freezing are not guaranteed to be deterministic, they do satisfy a
related property that \either{I}{we} call \emph{quasi-determinism}: all executions
that produce a final value produce the \emph{same} final value.  To
put it another way, a quasi-deterministic program can be trusted to
never change its answer due to nondeterminism; at worst, it might
raise an exception on some runs.  This exception can in principle
pinpoint the exact pair of freeze and write operations that are
racing, greatly easing debugging.

In general, the ability to make exact observations of the contents of
data structures is in tension with the goal of guaranteed determinism.
Since pushing towards full-featured, general monotonic data structures
leads to flirtation with nondeterminism, perhaps the best way of
ultimately getting deterministic outcomes is to traipse a short
distance into nondeterministic territory, and make our way back.  The
identification of quasi-deterministic programs as a useful
intermediate class of programs is a contribution of \either{this dissertation}{our work}.
That said, in many cases the @freeze@ construct is only used as the
very final step of a computation: after a global barrier, freezing is
used to extract an answer.  In this common case, determinism is
guaranteed, since no writes can subsequently occur.

\either{I}{We} will refer to the LVars model, extended with handlers, quiescence,
and freezing, as the \emph{LVish model}.  \either{The rest of this chapter is
organized as follows: in Section~\ref{s:quasi-informal}, I}{In this section, we first} introduce
the LVish programming model informally, through a series of examples.
\either{I}{We} will also return to the graph traversal \either{I}{we} discussed above and show
how to implement it using the LVish Haskell library (which \either{I}{we} will go
on to discuss the internals of in \either{Chapter}{Section}~\ref{ch:lvish}).  Then, in
Section~\ref{s:quasi-formal}, \either{I}{we} formalize the LVish model by extending
the $\lambdaLVar$ calculus of \either{Chapter}{Section}~\ref{ch:lvars} to add support
for handlers, quiescence, and freezing, calling the resulting language
$\lambdaLVish$.  Along with handlers, quiescence, and freezing, \either{I}{we} add
support for the arbitrary update operations described in
Section~\either{\ref{subsection:lvars-generalizing-from-least-upper-bound-writes}}{\ref{s:lvars-generalizing}}.
Finally, the main technical result of this \either{chapter}{section} is a proof of
quasi-determinism for
$\lambdaLVish$~(Section~\ref{s:quasi-proof-of-quasi-determinism}). Just
as with the determinism proof \either{I gave}{} for $\lambdaLVar$ in
\either{Chapter}{Section}~\ref{ch:lvars}, which relies on the Independence lemma
(Lemma~\ref{lem:lvars-independence}), the quasi-determinism proof for
$\lambdaLVish$ relies on a ``frame property'', the Generalized
Independence lemma (Lemma~\ref{lem:generalized-independence}).  As \either{I}{we}
explain in Section~\ref{subsection:quasi-generalized-independence},
the Generalized Independence lemma updates the original Independence
lemma to account for both freezing and the arbitrary update operations
that $\lambdaLVish$ allows.
