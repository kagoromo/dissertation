The LVars programming model presented in Chapter~\ref{ch:lvars} is
based on the idea of \emph{monotonic data structures}, in which (1)
information can only be added, never removed, and (2) the order in
which information is added is not observable.  A paradigmatic example
is a set that supports insertion but not removal, but there are many
others.  In the LVars model, all shared data structures (called LVars)
are monotonic, and the states that an LVar can take on form a
\emph{lattice}.  Writes to an LVar must correspond to a least upper
bound operation in the lattice, which means that they monotonically
increase the information in the LVar, and that they commute with one
another.  But commuting writes are not enough to guarantee
determinism: if a read can observe whether or not a concurrent write
has happened, then it can observe differences in scheduling.  So, in
the LVars model, the answer to the question ``has a write occurred?''
(\ie, is the LVar above a certain lattice value?)  is always
\emph{yes}; the reading thread will block until the LVar's contents
reach a desired threshold.  In a monotonic data structure, the absence
of information is transient---another thread could add that
information at any time---but the presence of information is forever.

The LVars model guarantees determinism and supports an unlimited
variety of shared data structures: anything viewable as a lattice.
However, it is not as general-purpose as one might hope.  Consider,
for instance, an algorithm for unordered graph traversal.  A typical
implementation involves a monotonically growing set of ``seen nodes'';
neighbors of seen nodes are fed back into the set until it reaches a
fixed point.  Such fixpoint computations are ubiquitous, and would
seem to be a perfect match for the LVars model due to their use of
monotonicity.  But they are not expressible using the threshold read
and least-upper-bound write operations described above.

The problem is that these computations rely on \emph{negative}
information about a monotonic data structure, \ie, on the
\emph{absence} of certain writes to the data structure.  In a graph
traversal, for example, neighboring nodes should only be explored if
the current node is \emph{not yet} in the set; a fixpoint is reached
only if no new neighbors are found; and, of course, at the end of the
computation it must be possible to learn exactly which nodes were
reachable (which entails learning that certain nodes were not).  But
in the LVars model, asking whether a node is in a set means waiting
until the node \emph{is} in the set, and it is not clear how to lift
this restriction while retaining determinism.

In this chapter, I describe two extensions to the basic LVars model of
Chapter~\ref{ch:lvars}:

\begin{itemize}
\item First, I extend the model with a primitive operation @freeze@
  for \emph{freezing} an LVar, which comes with the following
  tradeoff: once an LVar is frozen, any further writes that would
  change its value instead throw an exception; on the other hand, it
  becomes possible to discover the exact value of the LVar, learning
  both positive and negative information about it, without blocking.
\item
  Second, I add the ability to attach \emph{event handlers} to an
  LVar.  When an event handler has been registered with an LVar, it
  invokes a \emph{callback function} to run asynchronously, whenever
  events arrive (in the form of monotonic updates to the LVar).
  Ordinary LVar reads encourage a synchronous, \emph{pull} model of
  programming in which threads ask specific questions of an LVar,
  potentially blocking until the answer is ``yes''.  Handlers, by
  contrast, support an asynchronous, \emph{push} model of programming.
  Crucially, it is possible to check for \emph{quiescence} of a
  handler, discovering that no callbacks are currently enabled---a
  transient, negative property.  Since quiescence means that there are
  no further changes to respond to, it can be used to tell that a
  fixpoint has been reached.
\end{itemize}

Putting these features together, one can write a parallel graph
traversal algorithm in the following simple fashion:

\lstinputlisting{chapter3/code/bfs_new.hs}

This code, written using the LVish Haskell library (described in
Chapter~\ref{ch:lvish}),\footnote{The \lstinline|Par| type constructor
  is the monad in which LVar computations live.}  discovers (in
parallel) the set of nodes in a graph @g@ reachable from a given node
@startV@, and is guaranteed to produce a deterministic result.  It
works by creating a fresh @Set@ LVar (corresponding to a lattice whose
elements are sets, with set union as least upper bound), and seeding
it with the starting node.  The @freezeSetAfter@ function combines the
two new constructs---freezing and event handlers---described above.
First, it installs the callback @handle@ as a handler for the @seen@
set, which will asynchronously put the neighbors of each visited node
into the set, possibly triggering further callbacks, recursively.
Second, when no further callbacks are ready to run---\ie, when the
@seen@ set has reached a fixpoint---@freezeSetAfter@ will freeze the
set and return its exact value.

Unfortunately, freezing does not commute with writes that change an
LVar.\footnote{The same is true for quiescence detection; see
  Section~\ref{sec:quiescence-informal}.}  If a freeze is interleaved
before such a write, the write will raise an exception; if it is
interleaved afterwards, the program will proceed normally.  It would
appear that the price of negative information is the loss of
determinism!

Fortunately, the loss is not total.  Although LVar programs with
freezing are not guaranteed to be deterministic, they do satisfy a
related property that I call \emph{quasi-determinism}: all executions
that produce a final value produce the \emph{same} final value.  To
put it another way, a quasi-deterministic program can be trusted to
never change its answer due to nondeterminism; at worst, it might
raise an exception on some runs.  This exception can in principle
pinpoint the exact pair of freeze and write operations that are
racing, greatly easing debugging.

In general, the ability to make exact observations of the contents of
data structures is in tension with the goal of guaranteed determinism.
Since pushing towards full-featured, general monotonic data structures
leads to flirtation with nondeterminism, perhaps the best way of
ultimately getting deterministic outcomes is to traipse a short
distance into nondeterministic territory, and make our way back.  The
identification of quasi-deterministic programs as a useful
intermediate class of programs is a contribution of this dissertation.
That said, in many cases the @freeze@ construct is only used as the
very final step of a computation: after a global barrier, freezing is
used to extract an answer.  In this common case, determinism is
guaranteed, since no writes can subsequently occur.

The rest of this chapter is organized as follows: in
Section~\ref{s:quasi-informal}, I explain how freezing and event
handlers work at a high level.  Then, in Section~\ref{s:quasi-formal},
I extend the $\lambdaLVar$ calculus of Chapter~\ref{ch:lvars} to add
support for event handlers and the @freeze@ operation, calling the
resulting language $\lambdaLVish$.  The main technical result of this
chapter is a proof of quasi-determinism for
$\lambdaLVish$~(Section~\ref{s:quasi-proof}). Just as with the
determinism proof I gave for $\lambdaLVar$ in Chapter~\ref{ch:lvars},
the quasi-determinism proof for $\lambdaLVish$ relies on an
Independence lemma (Section~\ref{subsection:quasi-independence}) that
captures the commutative effects of LVar computations.  Later, in
Chapter~\ref{ch:lvish}, I will go on to describe the implementation of
LVish, a Haskell library for practical deterministic and
quasi-deterministic parallel programming, which is based on the
concepts presented in this chapter.

\TODO{Figure out if the stuff from the ``Safe, limited
  nondeterminism'' section that was cut from Chapter~\ref{ch:lvars}
  belongs in this chapter anywhere.}

%% In practice, a major problem with nondeterministic programs is that
%% they can {\em silently} go wrong.  Most parallel programming models
%% are {\em unsafe} in this sense, but we may classify a nondeterministic
%% language as {\em safe} if all occurrences of nondeterminism---that is,
%% execution paths that would yield a wrong answer---are trapped and
%% reported as errors.  This notion of \emph{safe nondeterminism} is
%% analogous to the concept of type safety: type-safe programs can throw
%% exceptions, but they will not ``go wrong''.  We find that there are
%% various extensions to a deterministic language that make it safely
%% nondeterministic.\footnote{For instance, while not recognized
%%   explicitly by the authors as such, a recent extension to CnC for
%%   memory management \cite{cnc-space-folding} incidentally fell into
%%   this category.}  Here, we will look at one such extension:
%% \emph{exact but destructive observations}.

%% We begin by noting that when the state of an LVar has come to
%% rest---when no more $\PUT$s will occur---then its final value is a
%% deterministic function of program inputs, and is therefore safe to
%% read directly, rather than through a thresholded $\GET$.  For
%% instance, once no more elements will be added to the @l_acc@
%% accumulator variable in the @bf_traverse@ example of
%% Figure~\ref{f:bfs-lvar}, it is safe to read the exact, complete set
%% contents.

%% The problem is determining automatically {\em when} an LVar has come
%% to rest; usually, the programmer must determine this based on the
%% control flow of the program.  We may, however, provide a mechanism for
%% the programmer to place their bet.  {\em If} the value of an LVar is
%% indeed at rest, then we do no harm to it by corrupting its state in
%% such a way that further modification will lead to an error.  We then
%% propose a new operation, @freeze@, that takes a pointer to an LVar
%% $l$, updates the store, setting $l$'s state to $\textit{probation}$,
%% and returns a singleton set containing the {\em exact} previous state
%% of $l$, rather than a lower bound on that state.  The idea is to
%% ensure that, after a @freeze@, any further operations on $l$ will go
%% awry: $\PUT$ operations will attempt to move the state of $l$ to
%% $\top$, resulting in $\error$.
