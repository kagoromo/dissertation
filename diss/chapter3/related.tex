\section{Related Work}
\label{section:related}

%% Cut for space -- LK

%% As we discussed in Section~\ref{section:intro}, what deterministic
%% parallel programming models have in common is that they all must do
%% something to restrict access to mutable state shared among
%% concurrent computations so that schedule nondeterminism cannot be
%% observed.  Depending on the model, restricting access to shared
%% mutable state might involve disallowing sharing entirely \cite{dph},
%% only allowing single assignments to shared references
%% \cite{Tesler-1968, IStructures, CnC}, allowing sharing only by a
%% limited form of message passing \cite{Kahn-1974}, ensuring that
%% concurrent accesses to shared state are disjoint \cite{dpj-oopsla},
%% resolving conflicting updates after the fact
%% \cite{concurrent-revisions-haskell11}, or some combination of these
%% approaches.  These constraints can be imposed at the language or API
%% level, within a type system, or at runtime.  In this section, we
%% compare LVish with various examples of previous work in the area.

\paragraph{Monotonic data structures: traditional approaches}

LVish builds on two long traditions of work on parallel programming
models based on monotonically-growing shared data structures:
\begin{itemize}
\item In {\em Kahn process networks} (KPNs) \cite{Kahn-1974}, as well
  as in the more restricted {\em synchronous data flow} systems
  \cite{Lee-sdn}, a network of processes communicate with each other
  through blocking FIFO channels with ever-growing {\em channel
    histories}.  Each process computes a sequential, monotonic
  function from the history of its inputs to the history of its
  outputs, enabling pipeline parallelism.  KPNs are the basis for
  deterministic stream-processing languages such as StreamIt
  \cite{streamit-asplos}.
\item In parallel {\em single-assignment languages}
  \cite{Tesler-1968}, ``full/empty'' bits are associated with heap
  locations so that they may be written to at most once.
  Single-assignment locations with blocking read semantics---that is,
  \emph{IVars} \cite{IStructures}---have appeared in Concurrent ML as
  @SyncVar@s \cite{reppy-cml-book}; in the Intel Concurrent
  Collections system \cite{CnC}; in languages and libraries for
  high-performance computing, such as Chapel \cite{chapel} and the
  Qthreads library \cite{qthreads}; and have even been implemented in
  hardware in Cray MTA machines \cite{cray-mta}.  Although most of
  these uses incorporate IVars into already-nondeterministic
  programming environments, Haskell's @Par@
  monad~\cite{monad-par}---on which our LVish implementation is
  based---uses IVars in a deterministic-by-construction setting,
  allowing user-created threads to communicate through IVars without
  requiring @IO@, so that such communication can occur anywhere inside
  pure programs.
\end{itemize}
LVars are general enough to subsume both IVars and KPNs: a lattice of
channel histories with a prefix ordering allows LVars to represent
FIFO channels that implement a Kahn process network, whereas an LVar
with ``empty'' and ``full'' states (where $\mathit{empty} <
\mathit{full}$) behaves like an IVar, as we described in
Section~\ref{section:lvars-refresher}.  Hence LVars provide a
framework for generalizing and unifying these two existing approaches
to deterministic parallelism.

\paragraph{Deterministic Parallel Java (DPJ)}

DPJ \cite{dpj-oopsla, dpj-hotpar09} is a deterministic language
consisting of a system of annotations for Java code.  A sophisticated
region-based type system ensures that a mutable region of the heap is,
essentially, passed linearly to an exclusive writer, thereby ensuring
that the state accessed by concurrent threads is disjoint.  DPJ does,
however, provide a way to unsafely assert that operations commute with
one another (using the @commuteswith@ form) to enable concurrent
mutation.

LVish differs from DPJ in that it allows overlapping shared state
between threads as the default.  Moreover, since LVar effects are
already commutative, we avoid the need for @commuteswith@ annotations.
Finally, it is worth noting that while in DPJ, commutativity
annotations have to appear in application-level code, in LVish only
the data-structure author needs to write trusted code. The application
programmer can run untrusted code that still enjoys a (quasi-)determinism guarantee, because only (quasi-)deterministic programs can be expressed as LVish @Par@
computations.

More recently, Bocchino \etal~\cite{dpj-popl} proposed a type and effect system that
allows for the incorporation of nondeterministic
sections of code in DPJ.  The goal here is different from ours: while they
aim to support \emph{intentionally} nondeterministic computations such
as those arising from optimization problems like branch-and-bound
search, LVish's quasi-determinism arises as a result of schedule
nondeterminism.

\paragraph{FlowPools}

Prokopec \etal~\cite{flowpools} recently proposed a data structure with
an API closely related to ideas in LVish: a FlowPool is a bag that allows
concurrent insertions but forbids removals, a {\tt seal} operation that forbids
further updates, and combinators like {\tt foreach} that invoke callbacks as
data arrives in the pool.  To retain determinism, the {\tt seal} operation
requires explicitly passing the expected bag \emph{size} as an argument, and the
program will raise an exception if the bag goes over the expected size.

While
this interface has a flavor similar to LVish, it lacks the ability to
detect quiescence, which is crucial for supporting examples like graph
traversal, and the {\tt seal} operation is awkward to use when the structure of
data is not known in advance.  By contrast, our @freeze@ operation
is more expressive and convenient, but moves the
model into the realm of quasi-determinism.  Another important difference is the
fact that LVish is \emph{data structure-generic}: both our formalism and our library
support an unlimited collection of data structures, whereas FlowPools 
are specialized to bags.
Nevertheless, FlowPools represent a ``sweet spot'' in the deterministic parallel design space: by
allowing handlers but not general freezing, they retain determinism
while improving on the expressivity of the original LVars model.  We
claim that, with our addition of handlers, LVish generalizes FlowPools
to add support for arbitrary lattice-based data structures.

\paragraph{Concurrent Revisions}

The Concurrent Revisions (CR)~\cite{concurrent-revisions-haskell11} programming model
 uses isolation types to distinguish regions of the heap shared
by multiple mutators.  Rather than enforcing exclusive access, CR
clones a copy of the state for each mutator, using a
deterministic ``merge function'' for resolving conflicts in local copies at join points.
Unlike LVish's least-upper-bound writes, CR merge functions are \emph{not} necessarily
commutative; the default CR merge function is ``joiner wins''.
Still, semilattices turn up in the metatheory of CR: in particular,
Burckhardt and Leijen~\cite{semantics-concurrent-revisions} show that,
for any two vertices in a CR revision diagram, there exists a
\emph{greatest common ancestor} state which can be used to determine
what changes each side has made---an interesting duality with our
model (in which any two LVar states have a lub).

While CR could be used to model similar types of data structures to LVish---if
versioned variables used least upper bound as their merge function for
conflicts---effects would only become visible at the end of parallel regions,
rather than $\LVish$'s asynchronous communication within parallel regions.  This
precludes the use of traditional lock-free data structures as a representation.

%% The management of shared variables in CR is tightly coupled to a
%% fork-join control structure, and the implementation of these variables
%% is similar to reduction variables in other languages (\eg, Cilk
%% {\em hyperobjects}).
%% CR charts an important new area in the deterministic-parallelism
%% design space, but one that differs significantly from
%% $\LVish$.

\paragraph{Conflict-free replicated data types}

In the distributed systems literature, \emph{eventually consistent}
systems based on \emph{conflict-free replicated data types}
(CRDTs)~\cite{crdts} leverage lattice properties to guarantee that
replicas in a distributed database eventually agree.  Unlike LVars,
CRDTs allow intermediate states to be observed: if two replicas are
updated independently, reads of those replicas may disagree until a
(least-upper-bound) merge operation takes place.  Various
data-structure-specific techniques can ensure that non-monotonic
updates (such as removal of elements from a set) are not lost.

The Bloom$^L$ language for distributed database programming
\cite{blooml} combines CRDTs with \emph{monotonic logic}, resulting in a
lattice-parameterized, confluent language that is a close relative of
LVish.  A monotonicity analysis pass rules out programs
that would perform non-monotonic operations on distributed data
collections, whereas in LVish, monotonicity is enforced by the LVar
API.

Future work will further explore the relationship between LVars and
CRDTs: in one direction, we will investigate LVar-based data
structures inspired by CRDTs that support non-monotonic operations; in
the other direction, we will investigate the feasibility and
usefulness of LVar threshold reads in a distributed setting.
