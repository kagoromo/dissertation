\chapter{Introduction}\label{ch:intro} % 1

Parallel programming---that is, writing programs that can take
advantage of parallel hardware to go faster---is notoriously
difficult.  A fundamental reason for this difficulty is that programs
can yield inconsistent results, or even crash, due to unpredictable
interactions between parallel tasks.

\emph{Deterministic-by-construction} parallel programming models,
though, offer the promise of freedom from subtle, hard-to-reproduce
nondeterministic bugs in parallel code.  While there are many ways to
construct deterministic parallel programs and to verify the
determinism of individual programs, only a
deterministic-by-construction programming model can provide a
\emph{language-level} guarantee of determinism:
deterministic programs are the only programs that can be expressed
within the model.

A deterministic-by-construction programming model is one that ensures
that all programs written using the model have the same
\emph{observable behavior} every time they are run.  How do we define
what is observable about a program's behavior?  Certainly, we do
\emph{not} wish to preserve behaviors such as running time across
multiple runs---ideally, a deterministic-by-construction parallel
program will run faster when more parallel resources are available.
Moreover, we do not want to count scheduling behavior as observable.
In fact, we want to specifically allow tasks to be scheduled
dynamically and unpredictably, without allowing such \emph{schedule
  nondeterminism} to affect the observable behavior of a program.
Therefore, we define the observable behavior of a program to be
\emph{the value to which the program evaluates}.

\lk{In my proposal, I had a footnote here: ``We assume that programs
  have no side effects other than state effects.'' I think I instead
  just want to say that we \emph{ignore} other side effects.  They can
  \emph{happen}; it's just that they don't count.}

Our definition of observable behavior ignores side effects other than
\emph{state}.  Even under this limited definition of what is
observable, though, sharing of state between parallel computations
raises the possibility of \emph{race conditions} that allow schedule
nondeterminism to be observed in the outcome of a program.  For
instance, if one computation writes $3$ to a shared location while
another writes $4$, then a subsequent third computation that reads and
returns the location's contents will nondeterministically return $3$
or $4$, depending on the order in which the first two computations
ran.  Therefore, if a parallel programming model is to guarantee
determinism by construction, it must necessarily limit sharing of
mutable state between parallel tasks in some way.

\section{The deterministic-by-construction parallel programming landscape}\label{s:intro-landscape}

There is long-standing work on deterministic-by-construction parallel
programming models that limit sharing of state between
tasks. Surveying the landscape of possibilities, we find that they
include:

\begin{itemize}
\item \emph{No-shared-state parallelism.}  One classic
  approach to guaranteeing determinism in a parallel programming model
  is to allow \emph{no} shared mutable state between tasks, forcing
  tasks to produce values independently.  An example of
  no-shared-state parallelism is pure functional programming with
  function-level task parallelism, or \emph{futures}---for instance,
  in Haskell programs that use the @par@ and @pseq@
  combinators~\cite{marlow-par}.  The key characteristic of this style
  of programming is lack of side effects: because programs don't have
  side effects, expressions can evaluate simultaneously without
  affecting the eventual value of the program.  Also belonging in this
  category are parallel programming models based on \emph{pure data
    parallelism}, such as Data Parallel Haskell~\cite{dph, dph-status}
  or the River Trail API for JavaScript~\cite{river-trail}, each of
  which extend existing languages with \emph{parallel array} data
  types and (observably) pure operations on them.
  \lk{Does it make sense to say that DPH is observably pure?  It does
    mutate arrays.}

\item \emph{Data-flow parallelism.}  In
  \emph{Kahn process networks} (KPNs)~\cite{Kahn-1974}, as well as in
  the more restricted \emph{synchronous data flow}
  systems~\cite{Lee-sdn}, a network of independent ``computing
  stations'' communicate with each other through first-in first-out
  (FIFO) queues, or \emph{channels}.  Reading data out of such a FIFO
  queue is a \emph{blocking} operation: once an attempt to read has
  started, a computing station cannot do anything else until the data
  to be read is available.  Each station computes a sequential,
  monotonic function from the \emph{history} of its input channels
  (\ie, the input it has received so far) to the history of its output
  channels (the output it has produced so far).  KPNs are the basis
  for deterministic stream-processing languages such as
  StreamIt~\cite{streamit-asplos}.

\item \emph{Single-assignment parallelism.}  In
  parallel \emph{single-assignment} languages, ``full/empty'' bits are
  associated with memory locations so that they may be written to at
  most once. Single-assignment locations with blocking read semantics
  are known as \emph{IVars}~\cite{IStructures} and are a
  well-established mechanism for enforcing determinism in parallel
  settings: they have appeared in Concurrent ML as
  @SyncVar@s~\cite{reppy-cml-book}; in the Intel Concurrent
  Collections (abbreviated ``CnC'') system~\cite{CnC}; and have even
  been implemented in hardware in Cray MTA machines~\cite{cray-mta}.

\item \emph{Imperative disjoint parallelism.}  Finally, yet another
  approach to guaranteeing determinism is to ensure that the state
  accessed by concurrent threads is \emph{disjoint}.\lk{This is the
    first place I've used the word ``concurrent''.  Should I explain
    concurrency vs. parallelism in a footnote or something?  Is it
    even a useful distinction in this context?}  Sophisticated
  permissions systems and type systems make it possible for imperative
  programs to mutate state in parallel, while guaranteeing that the
  same state is not accessed simultaneously by multiple threads.  We
  refer to this style of programming as \emph{imperative disjoint
    parallelism}, with Deterministic Parallel Java
  (DPJ)~\cite{dpj-oopsla} as a prominent example.
\end{itemize}
The four parallel programming models listed above---no-shared-state
parallelism, data-flow parallelism, single-assignment parallelism, and
imperative disjoint parallelism---all seem to comprise\lk{``have''?
  ``embody''?} rather different mechanisms for exposing parallelism
and for ensuring determinism.  If we view these different programming
models as a toolkit of unrelated choices, though, it is not clear how
to proceed when we want to implement an application with multiple
parallelizable components that are best suited to different
programming models.  For example, suppose we have an application in
which we wish to use data-flow pipeline parallelism via FIFO queues,
but also disjoint parallel mutation of arrays.  It is not obvious how
to compose two programming models that each only allow communication
through a single type of shared data structure---or, if we do manage
to compose them, whether or not the determinism guarantee of the
individual models is preserved by their composition.  Hence we seek a
general, broadly-applicable model for deterministic parallel
programming that is not tied to a particular data structure.

\section{Lattice-based, monotonic data structures as a basis for deterministic parallelism}\label{s:intro-monotonic}

In KPNs and other data-flow models, communication takes place over
blocking FIFO queues with ever-increasing \emph{channel histories},
while in IVar-based programming models such as CnC and monad-par, a
shared data store of blocking single-assignment memory locations grows
monotonically.  Hence \emph{monotonic data structures}---data
structures to which information can only be added and never
removed---emerge as a common theme of guaranteed-deterministic
programming models.\footnote{We will later refine this definition of
  monotonic data structures to mean data structures to which
  information can only be added and never removed, \emph{and} for
  which the order in which information is added is not
  observable.\TODO{Add appropriate forward reference here.}}

In this dissertation, I show that \emph{lattice-based} data
structures, or \emph{LVars}, are the foundation for a model of
deterministic-by-construction parallel programming that allows a more
general form of communication between tasks than previously existing
guaranteed-deterministic models allowed.  LVars generalize IVars and
are so named because the states an LVar can take on are elements of an
application-specific \emph{lattice}.\footnote{As I will explain in
  Chapter~\ref{ch:lvars}, what I am calling a ``lattice'' here really
  need only be a {\em bounded join-semilattice} augmented with a
  greatest element $\top$.}  This application-specific lattice
determines the semantics of the @put@ and @get@ operations that
comprise the interface to LVars (which I will explain in detail in
Chapter~\ref{ch:lvars}):
\begin{itemize}
\item The @put@ operation can only change an LVar's state in a way
  that is {\em monotonically increasing} with respect to the lattice,
  because it takes the least upper bound of the current state and the
  new state.
\item The @get@ operation allows only limited observations of the
  state of an LVar.  It requires the user to specify a \emph{threshold
    set} of minimum values that can be read from the LVar, where every
  two elements in the threshold set must have the lattice's greatest
  element $\top$ as their least upper bound.\footnote{See
    Chapter~\ref{ch:lvars} for a generalization of this
    definition.\TODO{Figure out what section to link to for
      generalized threshold sets.}}  A call to @get@ blocks until the
  LVar in question reaches a (unique) value in the threshold set, then
  unblocks and returns that value.
\end{itemize}
Together, monotonically increasing writes via @put@ and threshold
reads via @get@ yield a deterministic-by-construction programming
model.  That is, a program in which @put@ and @get@ operations on
LVars are the only side effects will have the same observable result
in spite of parallel execution and schedule nondeterminism.  \lk{Maybe
  we don't need the next sentence at all; maybe it's covered by the
  ``organization'' bullet points below.} As we will see in
Chapter~\ref{ch:lvars}, no-shared-state parallelism, data-flow
parallelism and single-assignment parallelism are all subsumed by the
LVars programming model, and as we will see in
Chapter~\ref{ch:lvish}\lk{Maybe refer to a specific section?},
imperative disjoint parallelism is compatible with LVars as well.

\section{Quasi-deterministic and event-driven programming with LVars}\label{s:intro-quasi}

The LVars model described above guarantees determinism and supports an
unlimited variety of shared data structures: anything viewable as a
lattice.  However, it is not as general-purpose as one might hope.
Consider, for instance, an algorithm for unordered graph traversal.  A
typical implementation involves a monotonically growing set of ``seen
nodes''; neighbors of seen nodes are fed back into the set until it
reaches a fixed point.  Such fixpoint computations are ubiquitous, and
would seem to be a perfect match for the LVars model due to their use
of monotonicity.  But they are not expressible using the threshold
@get@ and least-upper-bound @put@ operations described above.

The problem is that these computations rely on \emph{negative}
information about a monotonic data structure, \ie, on the
\emph{absence} of certain writes to the data structure.  In a graph
traversal, for example, neighboring nodes should only be explored if
the current node is \emph{not yet} in the set; a fixpoint is reached
only if no new neighbors are found; and, of course, at the end of the
computation it must be possible to learn exactly which nodes were
reachable (which entails learning that certain nodes were not).  In
Chapter~\ref{ch:quasi}, I describe two extensions to the basic LVars
model that make such computations possible:
\begin{itemize}
\item First, I describe how to add a primitive operation @freeze@ for
  \emph{freezing} an LVar, which allows its contents to be read
  immediately and exactly, rather than the blocking threshold read
  that @get@ allows.  The @freeze@ primitive imposes the following
  trade-off: once an LVar has been frozen, any further writes that
  would change its value instead raise an exception; on the other
  hand, it becomes possible to discover the exact value of the LVar,
  learning both positive and negative information about it, without
  blocking.  Therefore, LVar programs that use @freeze@ are \emph{not}
  guaranteed to be deterministic, because they could
  nondeterministically raise an exception depending on how @put@ and
  @freeze@ operations are scheduled.  However, we \emph{can} guarantee
  that such programs satisfy \emph{quasi-determinism}: all executions
  that produce a final value produce the \emph{same} final value.
\item Second, I describe how to add the ability to attach \emph{event
  handlers} to an LVar.  When an event handler has been registered
  with an LVar, it invokes a \emph{callback function} to run,
  asynchronously, whenever events arrive (in the form of monotonic
  updates to the LVar).  Crucially, it is possible to check for
  \emph{quiescence} of a group of handlers, discovering that no
  callbacks are currently enabled---a transient, negative property.
  Since quiescence means that there are no further changes to respond
  to, it can be used to tell that a fixpoint has been reached.
\end{itemize}
Of course, since more events could arrive later, there is no way to
guarantee that quiescence is permanent---but since the contents of the
LVar being written to can only be read through @get@ or @freeze@
operations anyway, early quiescence poses no risk to determinism or
quasi-determinism, respectively.  In fact, freezing and quiescence
work particularly well together because freezing provides a mechanism
by which we can safely ``place a bet'' that all writes have completed.
Hence freezing and handlers make possible fixpoint computations like
the graph traversal described above.  Moreover, if we can ensure that
the freeze does indeed happen after all writes have completed, then we
can ensure that the computation is deterministic, and it is possible
to enforce this ``freeze-last'' idiom at the implementation level, as
I discuss below (and, in more detail, in
Chapter~\ref{ch:lvish}\lk{Refer to a specific section?}).

\section{The LVish library}\label{s:intro-lvish}

To demonstrate the practicality of the LVars programming model, in
Chapter~\ref{ch:lvish} I will describe
\emph{LVish},\footnote{Available at
  \url{http://hackage.haskell.org/package/lvish}.} a Haskell library
for deterministic and quasi-deterministic programming with LVars.

LVish provides a @Par@ monad for encapsulating parallel computation
and enables a notion of lightweight, library-level threads to be
employed with a custom work-stealing scheduler.\footnote{The
  \lstinline|Par| monad exposed by LVish generalizes the original
  \lstinline|Par| monad exposed by the \emph{monad-par} library
  ({\url{http://hackage.haskell.org/package/monad-par}}, described by
  Marlow \etal~\cite{monad-par}), which allows determinism-preserving
  communication between threads, but only through IVars, rather than
  LVars.}  LVar computations run inside the @Par@ monad, which is
indexed by an \emph{effect level}, allowing fine-grained specification
of the effects that a given computation is allowed to perform.  For
instance, since @freeze@ introduces quasi-determinism, a computation
indexed with a deterministic effect level is not allowed to use
@freeze@.  Thus, the \emph{static type} of an LVish computation
reflects its determinism or quasi-determinism guarantee.  Furthermore,
if a @freeze@ is guaranteed to be the \emph{last} effect that occurs
in a computation, then it is impossible for that @freeze@ to race with
a @put@, ruling out the possibility of a run-time @put@-after-@freeze@
exception.  LVish exposes a @runParThenFreeze@ operation that captures
this ``freeze-last'' idiom and has a deterministic effect level.

LVish also provides a variety of lattice-based data structures (\eg,
sets, maps, graphs) that support concurrent insertion, but not
deletion, during @Par@ computations.  In addition to those that LVish
provides, users may implement their own lattice-based data structures,
and LVish provides tools to facilitate the definition of user-defined
LVars.  I will describe the proof obligations for data structure
implementors and give examples of applications that use user-defined
LVars as well as those that the library provides.

In addition to discussing the implementation of the LVish library and
introducing the above features with examples, Chapter~\ref{ch:lvish}
illustrates LVish through three case studies, drawn from my
collaborators' and my experience using the LVish library, all of which
make use of handlers and freezing:
\begin{itemize}
\item First, I describe using LVish to implement a parallel,
  pipelined, breadth-first graph traversal in which a (possibly
  expensive) function @f@ is mapped over each node in a connected
  component of a graph.  The idea is that the set of results of
  applying @f@ to nodes become incrementally available to other
  computations.
  %% For this case study, I will reimplement the
  %% breadth-first traversal algorithm that appears in Kuper and
  %% Newton~\cite{LVars-paper}, which I will update in two ways.  First,
  %% the original version uses @runParIO@ and a ``consume'' operation
  %% that was a precursor to @freeze@, and I will refactor it to use the
  %% safer @runParThenFreeze@.  Second, although the original version is
  %% pipelined in that it begins \emph{invoking} @f@ on already-found
  %% nodes before all the nodes in the component have been traversed, it
  %% does not take advantage of this early invocation to do something
  %% useful with the early result of @f@; however, it should be
  %% straightforward to do so using event handlers.
\item Second, I describe using LVish to parallelize a control flow
  analysis ($k$-CFA) algorithm.  The goal of $k$-CFA is to compute the
  flow of values to expressions in a program.  The $k$-CFA algorithm
  proceeds in two phases: first, it explores a graph of \emph{abstract
    states} of the program; then, it summarizes the results of the
  first phase.  Using LVish, these two phases can be pipelined in a
  manner similar to the pipelined breadth-first graph traversal
  described above; moreover, the original graph exploration phase can
  be internally parallelized.  I contrast the LVish implementation
  with the original sequential implementation and give performance
  results.
\item Third, I describe using LVish to parallelize
  \emph{PhyBin}~\cite{PhyBin}, a bioinformatics application for
  comparing genealogical histories (phylogenetic trees) that relies
  heavily on a parallel tree-edit distance algorithm~\cite{hashrf}.
  In addition to handlers and freezing, the PhyBin application relies
  on the ability to perform writes to LVars that are commutative and
  inflationary with respect to the lattice in question, but \emph{not}
  idempotent (in contrast to the least-upper-bound writes discussed
  above, which are idempotent).  I argue that these non-idempotent
  writes, which we call @bump@ operations, preserve determinism as
  long as programs do not use @put@ and @bump@ on the same LVar, a
  property that can be statically enforced by the aforementioned
  effect specification system in LVish.
\end{itemize}

\section{Deterministic threshold queries of distributed data structures}\label{s:intro-cvrdts}

The LVars model is closely related to the concept of
\emph{conflict-free replicated data types} (CRDTs)~\cite{crdts} for
enforcing \emph{eventual consistency}~\cite{vogels-ec} of replicated
objects in a distributed system.  In particular, \emph{state-based} or
\emph{convergent} replicated data types, abbreviated as
\emph{CvRDTs}~\cite{crdts, crdts-tr}, leverage the mathematical
properties of join-semilattices to guarantee that all replicas of an
object (for instance, in a distributed database) eventually agree.

Although CvRDTs are provably eventually consistent, queries of CvRDTs
(unlike threshold reads of LVars) nevertheless allow inconsistent
intermediate states of replicas to be observed.  That is, if two
replicas of a CvRDT object are updated independently, reads of those
replicas may disagree until a (least-upper-bound) \emph{merge}
operation takes place.

Taking inspiration from LVar-style threshold reads, in
Chapter~\ref{ch:threshold-queries} I show how to extend CvRDTs to
support provably deterministic, \emph{strongly consistent} queries
using a mechanism called \emph{threshold queries} (or, seen from
another angle, I show how to extend threshold reads from a
shared-memory setting to a distributed one).  The threshold query
technique generalizes to any lattice, and hence any CvRDT, and allows
deterministic observations to be made of replicated objects before the
replicas' states have converged.  This work has immediate practical
relevance since, while many real distributed database systems allow a
mix of eventually consistent and strongly consistent queries, CvRDTs
only support the former, and threshold queries extend the CvRDT model
to support both.

\section{Thesis statement, and organization of the rest of this dissertation}\label{s:thesis}

With the above background, I can state my thesis:\lk{This format
  ripped off from Josh Dunfield.}
\begin{quote}
  Lattice-based data structures are a general and practical foundation
  for deterministic and quasi-deterministic parallel and distributed
  programming.
\end{quote}
The rest of this dissertation supports my thesis as follows:
\begin{itemize}
  \item \emph{Lattice-based data structures}: In
    Chapter~\ref{ch:lvars}, I formally define LVars and use them to
    define $\lambdaLVar$, a call-by-value parallel calculus with
    shared state, including a runnable version implemented in PLT
    Redex~\cite{redex-book} for interactive experimentation.  In
    Chapter~\ref{ch:quasi}, I extend $\lambdaLVar$ to add support for
    event handlers and the @freeze@ operation, calling the resulting
    language $\lambdaLVish$.\footnote{$\lambdaLVish$ is the
      \emph{LVish calculus} described in Kuper
      \etal~\cite{Freeze-paper}.  In this dissertation, I call it
      $\lambdaLVish$ to avoid confusion with LVish, the Haskell
      library I describe in Chapter~\ref{ch:lvish}.}

  \item \emph{general}: In Chapter~\ref{ch:lvars}, I defend the
    generality of the LVars model by showing how previously existing
    deterministic parallel programming models can be expressed with
    LVish.  This is possible because the definition of $\lambdaLVar$
    is parameterized by the choice of lattice.  For example, a lattice
    of channel histories with a prefix ordering allows LVars to
    represent FIFO channels that implement a Kahn process network,
    whereas instantiating $\lambdaLVar$ with a lattice with one
    ``empty'' state and multiple ``full'' states (where $\forall{i}.\;
    \mathit{empty} < \mathit{full_i}$) results in a parallel
    single-assignment language.  Hence $\lambdaLVar$ is actually a
    \emph{family} of calculi, varying by choice of lattice.

  \item \emph{practical}: In Chapter~\ref{ch:lvish}, I defend the
    practicality of LVars by describing the LVish Haskell library and
    demonstrating how it is used for practical programming with the
    three case studies described above, including performance results.

  \item \emph{deterministic}: In Chapter~\ref{ch:lvars}, I defend the
    claim that the basic LVars model guarantees determinism by giving
    a proof of determinism for $\lambdaLVish$, including the
    aforementioned @put@, @get@, and non-idempotent @bump@ operations
    on LVars.

  \item \emph{quasi-deterministic}: In Chapter~\ref{ch:quasi}, I
    defend this claim by giving a proof of quasi-determinism for the
    full $\lambdaLVish$ calculus with the additions of the @freeze@
    operation and event handlers.

  \item \emph{distributed programming}: In Chapter~\ref{ch:crdts}, I
    defend the claim that the LVars programming model is applicable to
    distributed programming by showing how to extend distributed
    replicated data structures with LVar-style threshold reads.
\end{itemize}

\section{Previously published work}

This dissertation draws heavily on the earlier work and writing
appearing in the following papers, written jointly with several
collaborators:\lk{This exact wording stolen from Aaron Turon.  maybe
  tweak it?}

\begin{itemize}
\item Lindsey Kuper and Ryan
  R. Newton. 2013. \href{http://doi.acm.org/10.1145/2502323.2502326}{LVars:
    lattice-based data structures for deterministic parallelism.} In
  \emph{Proceedings of the 2nd ACM SIGPLAN workshop on Functional
    high-performance computing} (FHPC '13).

\item Lindsey Kuper, Aaron Turon, Neelakantan R. Krishnaswami, and
  Ryan
  R. Newton. 2014. \href{http://doi.acm.org/10.1145/2535838.2535842
  }{Freeze after writing: quasi-deterministic parallel programming
    with LVars.} In \emph{Proceedings of the 41st ACM SIGPLAN-SIGACT
    Symposium on Principles of Programming Languages} (POPL '14).

\item Lindsey Kuper, Aaron Todd, Sam Tobin-Hochstadt, and Ryan
  R. Newton. 2014. \href{http://doi.acm.org/10.1145/2594291.2594312
  }{Taming the parallel effect zoo: extensible deterministic
    parallelism with LVish.} In \emph{Proceedings of the 35th ACM
    SIGPLAN Conference on Programming Language Design and
    Implementation} (PLDI '14).

\item Lindsey Kuper and Ryan
  R. Newton. \href{http://www.cs.indiana.edu/~lkuper/papers/threshold-queries-draft.pdf}{Deterministic
    threshold queries of distributed data structures.} Draft,
  2014.\TODO{Update this if the paper is accepted.}

\end{itemize}

\lk{Also, in individual chapters, say, ``The material in this chapter
  is based on research done jointly with...''  and cite the papers.}
