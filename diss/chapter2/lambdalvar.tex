\section{$\lambdaLVar$: syntax and semantics}\label{s:lvars-lambdalvar}

\FigLambdaLVarGrammar

\FigLambdaLVarReductionSemantics

\FigLambdaLVarContextSemantics

\lk{Maybe this should be explained more slowly---that is, maybe I
  should individually go through each thing in the grammar and say
  what it is.  I wouldn't do that in a conference paper, but...this
  isn't a conference paper.}

The syntax of $\lambdaLVar$ appears in
Figure~\ref{f:lvars-lambdaLVar-syntax}, and
Figures~\ref{f:lvars-lambdaLVar-reduction-semantics},
and~\ref{f:lvars-lambdaLVar-context-semantics} together give the
operational semantics.

\TODO{Revise this to explain the split semantics.}

Both the syntax and semantics are parameterized by the lattice $(D,
\userleq, \bot, \top)$.  The reduction relation $\parstepsto$ is
defined on \emph{configurations} $\config{S}{e}$ comprising a store
and an expression.  The \emph{error configuration}, written $\error$,
is a unique element added to the set of configurations, but
$\config{\topS}{e}$ is equal to $\error$ for all expressions $e$.  The
metavariable $\conf$ ranges over configurations.

$\lambdaLVar$ uses a reduction semantics based on \emph{evaluation
  contexts}.  The {\sc E-Eval-Ctxt} rule is a standard context rule,
allowing reductions to apply within a context.  The choice of context
determines where evaluation can occur; in $\lambdaLVar$, the order of
evaluation is nondeterministic (that is, a given expression can
generally reduce in more than one way), and so it is generally
\emph{not} the case that an expression has a unique decomposition into
redex and context.  For example, in an application $\app{e_1}{e_2}$,
either $e_1$ or $e_2$ might reduce first.  The nondeterminism in
choice of evaluation context reflects the nondeterminism of scheduling
between concurrent threads, and in $\lambdaLVar$, the arguments to
@get@, @put@, and application expressions are \emph{implicitly}
evaluated concurrently.

The rules {\sc E-New}, {\sc E-Put}/{\sc E-Put-Err}, and {\sc E-Get}
respectively express the semantics of the @new@, @put@, and @get@
operations described in
Section~\ref{subsection:lvars-communication-primitives}.  The {\sc
  E-New} rule creates a new binding in the store and returns a pointer
to it; the side condition $l \notin \dom{S}$ ensures that $l$ is a
fresh location.  The {\sc E-Put} rule updates the store and returns
$\unit$, the unit value.  The {\sc E-Put-Err} rule applies when a
@put@ to a location would take its state to $\top$; in that case, the
semantics steps to $\error$.  The incompatibility of the threshold set
argument to @get@ is enforced in the {\sc E-Get} rule by the
$\incomp{T}$ premise, which requires that the least upper bound of any
two distinct elements in $T$ must be $\top$.

\subsection{Fork-join parallelism}\label{subsection:fork-join}

$\lambdaLVar$ has a call-by-value semantics: arguments must be fully
evaluated before function application ($\beta$-reduction, modeled by
the {\sc E-Beta} rule) can occur.  I exploit this property to define a
syntactic sugar @let par@ for \emph{parallel composition}, which
computes two subexpressions $e_1$ and $e_2$ in parallel before
computing $e_3$:
\begin{displaymath}
\begin{minipage}[b]{2in}
  \begin{equation*}
\begin{split}
& \LETPAR ~x = e_1 \\ 
& \letparspace ~y = e_2 \\
& \letspace \IN~e_3 
\end{split}
\end{equation*}
\end{minipage}
\begin{minipage}[b]{1in}
\centering
$\defeq$
\end{minipage}
\begin{minipage}[b]{2in}
\begin{equation*}
  \app{(\app{(\lam{x}{(\lam{y}{e_3})})}{e_1})}{e_2}
\end{equation*}
\end{minipage}
\end{displaymath}

Although $e_1$ and $e_2$ can be evaluated in parallel, $e_3$ cannot be
evaluated until both $e_1$ and $e_2$ are values, because the
call-by-value semantics does not allow $\beta$-reduction until the
operand is fully evaluated, and because it further disallows reduction
under $\lambda$-terms (sometimes called ``full $\beta$-reduction'').
In the terminology of parallel programming, a @let par@ expression
executes both a \emph{fork} and a \emph{join}.  Indeed, it is common
for fork and join to be combined in a single language construct, for
example, in languages with parallel tuple expressions such as
Manticore~\cite{manticore_parallel_tuples}.

\begin{figure}[tb]
  \centering 
\includegraphics[width=4in]{chapter2/figures/lvars-series-parallel.pdf} 
\caption{A series-parallel graph induced by parallel
  $\lambda$-calculus evaluation (a); a non-series-parallel graph
  induced by \lstinline|put|/\lstinline|get| operations (b).}
  \label{f:lvars-series-parallel}
\end{figure}

Since @let par@ expresses \emph{fork-join} parallelism, the evaluation
of a program comprising nested @let par@ expressions would induce a
runtime dependence graph like that pictured in
Figure~\ref{f:lvars-series-parallel}(a).  The $\lambdaLVar$ language
(minus @put@ and @get@) can support any \emph{series-parallel}
dependence graph.  Adding communication through @put@ and @get@
introduces ``lateral'' edges between branches of a parallel
computation, as in Figure~\ref{f:lvars-series-parallel}(b).  This adds
the ability to construct arbitrary non-series-parallel dependency
graphs, just as with \emph{first-class
  futures}~\cite{beyond-nested-workstealing}.

Because the $\lambdaLVar$ semantics does not reduce under
$\lambda$-terms, we can sequentially compose $e_1$ before $e_2$ by
writing $\letexp{\_}{e_1}{e_2}$, which desugars to
$\app{(\lam{\_}{e_2})}{e_1}$.  Sequential composition is useful for,
for instance, allocating a new LVar before beginning a sequence of
side-effecting @put@ and @get@ operations on it.
